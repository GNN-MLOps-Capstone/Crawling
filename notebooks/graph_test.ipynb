{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T05:17:00.486025Z",
     "start_time": "2025-11-13T05:17:00.482066Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8e97e6642eda59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T04:38:33.308649Z",
     "start_time": "2025-11-13T04:38:32.904603Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './news_final.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./news_final.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcp949\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './news_final.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./news_final.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547a6581addd9f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T04:39:16.069897Z",
     "start_time": "2025-11-13T04:38:33.309845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 정규식 패턴 (일부): SM\\ Life\\ Design|피엔케이피부임상연구센타|대신밸런스제19호스팩|대신밸런스제18호스팩|대신밸런스제17호스팩|대신밸런스제16호스팩|큐리옥스바이오시스템즈|프레스티지바이오로직...\n",
      "\n",
      "--- 결과 ---\n",
      "      crawled_news_id                                          title  \\\n",
      "0               16388            계엄날 한동훈 체포조장 , 포고문 버리고 편의점에서 시간 끌었다   \n",
      "1               16391                         \"장난치면 패가망신\" 주가조작 칼 빼든다   \n",
      "2               16387  \"깨 많이, 콩 많이\" 경쟁하며 송편 빚고, 전 부치던 부엌 응답하라 90'...   \n",
      "3               16397             강훈식 \"김현지, 직언 참모 인사, 이미 한 달 전부터 준비\"   \n",
      "4               16386         5일째 파업 인천공항 노동자들 공항 모·자회사, 시민·직원 불편...   \n",
      "...               ...                                            ...   \n",
      "7538            24296         조주완 LG전자 CEO, 사우디 정부와 네옴시티 냉각솔루션 협력 논의   \n",
      "7539            24295           민형배 의원, '글로컬대학 결과' SNS 올렸다가 삭제 '구설수'   \n",
      "7540            24301              보험직썰 미국계 달튼 vs 토종파 MBK 이들 출자자 차이는   \n",
      "7541            24294                농협재단, 우리 쌀 나눔으로 취약계층과 농업인 행복 지원   \n",
      "7542            24293                      농협 축산경제, 농·축협 수의사 기술교육 실시   \n",
      "\n",
      "              pub_date                                               text  \\\n",
      "0     2025/10/05 13:45  법정 417호, 내란의 기록 윤석열 전 대통령이 불법 계엄을 선포한 두 자정을 넘긴...   \n",
      "1     2025/10/05 13:35  이재명 대통령은 '코스피 5,000시대'를 목표로 삼고 있습니다. 현 정부가 이 목...   \n",
      "2     2025/10/05 13:31  온갖 종류 전부터 푸짐한 갈비찜까지 간편하게 변화한 차례상 고물가·잔반 부담스러워 ...   \n",
      "3     2025/10/05 13:20  강훈식 대통령 비서실장이 이재명 대통령의 측근으로 꼽 는 김현지 제1부속실장에 대해...   \n",
      "4     2025/10/05 13:13  최근 인천국제공항 내 직원 근무 공간에 쓰레기 더미가 쌓여 있는 모습. 민주노총 공...   \n",
      "...                ...                                                ...   \n",
      "7538  2025/09/26 14:28  청년일보 LG전자는 조주완 CEO가 26일 서울 중구 롯데호텔에서 사우디아라비아 칼...   \n",
      "7539  2025/09/26 14:28  교육부 발표도 전에 '성급한 행동' 지적 내년 지방선거와 연관 해석도 민형배 의원 ...   \n",
      "7540  2025/09/26 14:26  챗GPT 생성 이미지. 국정감사와 주주총회를 앞둔 기업계에서 2곳의 사모운용펀드가 ...   \n",
      "7541  2025/09/26 14:26  10억원 규모 우리 쌀 나눔으로 전국 취약계층 복지지원 쌀 과자 제조기 보급·활용....   \n",
      "7542  2025/09/26 14:26  수의 전문인력 양성으로 축산농가 조합원 진료서비스 수준 향상 농협경제지주가 지난 2...   \n",
      "\n",
      "                                       tfidf_keywords  \\\n",
      "0              국회, 방첩, 지시, 계엄, 체포, 혐의, 재판, 부대, 출석, 내란   \n",
      "1        불공정, 거래, 자본시장, 제재, 코스피, 조작, 합동, 주가, 주식시장, 정부   \n",
      "2             명절, 음식, 송편, 풍경, 북적, 가족, 며칠, 연휴, 차례상, 차례   \n",
      "3          실장, 부속, 인사, 김현지, 대통령, 대변인, 김남준, 서관, 임명, 무비   \n",
      "4         인천공항, 파업, 지부, 쓰레기, 노동자, 공항, 자회사, 노조, 근무, 불편   \n",
      "...                                               ...   \n",
      "7538  데이터, 중동, 사우디, 사우디아라비아, 냉각, 볼트, 센터, 솔루션, 사업, 셰이커   \n",
      "7539          대학, 교육부, 의원, 발표, 내용, 지역, 삭제, 언급, 광주, 사안   \n",
      "7540      펀드, 국민연금, 주주, 홀딩스, 자금, 부회장, 기업, 주의, 행동, 글로벌   \n",
      "7541        농협, 계층, 취약, 경상북도, 재단, 전달, 농업인, 과자, 소비, 복지   \n",
      "7542           축산, 수의, 농가, 교육, 진료, 농협, 전문, 동물, 양성, 향상   \n",
      "\n",
      "                              keyword                    stock  \n",
      "0                  국회, 계엄, 체포, 재판, 내란                       대원  \n",
      "1              불공정, 거래, 자본시장, 제재, 코스피                           \n",
      "2                 명절, 음식, 가족, 송편, 차례상                       대상  \n",
      "3                실장, 부속, 대통령, 인사, 김현지                           \n",
      "4              인천공항, 파업, 노동자, 쓰레기, 불편                           \n",
      "...                               ...                      ...  \n",
      "7538  LG전자, 사우디아라비아, 데이터센터, 냉각솔루션, 중동           LG전자,레이,LG,링크드  \n",
      "7539              대학, 교육부, 의원, 발표, 지역                           \n",
      "7540             펀드, 국민연금, 주주, 기업, 행동  콜마홀딩스,콜마비앤에이치,CJ제일제당,대상  \n",
      "7541             농협, 계층, 취약, 경상북도, 재단                       농심  \n",
      "7542               축산, 수의, 농협, 전문, 진료                 대상,대동,효성  \n",
      "\n",
      "[7543 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 임시 종목 파싱 코드\n",
    "import lxml\n",
    "import urllib.request  # urllib.request 모듈 추가\n",
    "import re\n",
    "\n",
    "# KRX 상장법인 현황 페이지 URL\n",
    "url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method=download'\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data_bytes = response.read()\n",
    "\n",
    "    df_krx = pd.read_html(\n",
    "        data_bytes,  \n",
    "        header=0,\n",
    "        converters={'종목코드': str},\n",
    "        flavor='lxml',\n",
    "        encoding='cp949' \n",
    "    )[0]\n",
    "\n",
    "    # '회사명' 컬럼을 리스트로 변환\n",
    "    stock_name_list = df_krx['회사명'].tolist()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"패키지가 설치되지 않았습니다. 'uv pip install pandas lxml'을 실행해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"데이터를 가져오는 중 오류가 발생했습니다: {e}\")\n",
    "    \n",
    "# 1. 정규식 패턴 생성\n",
    "#    - re.escape(): '(주)'나 'LG+U'처럼 정규식 특수문자가 포함된 회사명을 안전하게 처리\n",
    "#    - .sort(key=len, reverse=True): 'SK하이닉스'가 'SK'보다 먼저 매칭되도록 긴 이름순으로 정렬\n",
    "escaped_names = sorted([re.escape(name) for name in stock_name_list], key=len, reverse=True)\n",
    "regex_pattern = '|'.join(escaped_names)\n",
    "\n",
    "print(f\"생성된 정규식 패턴 (일부): {regex_pattern[:100]}...\")\n",
    "\n",
    "# 2. findall로 text 컬럼에서 모든 회사명을 리스트로 추출\n",
    "#    - .str.findall()은 각 행에서 매칭되는 모든 이름을 리스트로 반환\n",
    "matches = df['text'].str.findall(regex_pattern)\n",
    "\n",
    "# 3. 추출된 리스트에서 중복 제거 (순서 유지)\n",
    "#    - .apply()를 사용해 각 행의 리스트(x)에 대해 dict.fromkeys를 적용\n",
    "#    - dict.fromkeys는 순서를 유지하면서 중복을 제거하는 가장 빠른 방법입니다.\n",
    "#    - isinstance(x, list)는 원본 text가 NaN일 경우 오류가 나는 것을 방지합니다.\n",
    "unique_matches = matches.apply(\n",
    "    lambda x: list(dict.fromkeys(x)) if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "# 4. 리스트를 ','로 구분된 문자열로 변환하여 새 컬럼에 할당\n",
    "#    - .str.join(',')은 ['삼성전자', 'SK하이닉스'] -> '삼성전자,SK하이닉스'로 바꿔줌\n",
    "df['stock'] = unique_matches.str.join(',')\n",
    "\n",
    "#5. keyword 열 삭제(임시)\n",
    "df = df.drop('keyword', axis=1)\n",
    "print(\"\\n--- 결과 ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e28cdde1a17b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T04:54:59.079746Z",
     "start_time": "2025-11-13T04:54:59.025649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1. 엣지 전처리 완료] ---\n",
      "뉴스-키워드 엣지 수: 75379\n",
      "뉴스-종목 엣지 수: 10953\n"
     ]
    }
   ],
   "source": [
    "## 1단계: 엣지(Edge) 전처리\n",
    "# 목표: 쉼표로 묶인 문자열을 분해하여 (뉴스 ID, 키워드) / (뉴스 ID, 종목) 엣지 리스트 생성\n",
    "\n",
    "def split_and_clean(series):\n",
    "    \"\"\"쉼표로 구분된 문자열을 분리하고, 공백을 제거하며, 빈 문자열을 필터링합니다.\"\"\"\n",
    "    return series.str.split(',').apply(\n",
    "        lambda x: [item.strip() for item in x if item.strip()]\n",
    "    )\n",
    "\n",
    "# 1. 키워드 엣지 생성\n",
    "df['keywords_list'] = split_and_clean(df['tfidf_keywords'])\n",
    "# (수정) 이름 충돌 방지를 위해 필요한 컬럼만 먼저 선택\n",
    "news_to_keyword_edges = df[['crawled_news_id', 'keywords_list']] \\\n",
    "    .explode('keywords_list') \\\n",
    "    .rename(columns={'keywords_list': 'keyword'}) \\\n",
    "    .dropna()\n",
    "\n",
    "# 2. 종목 엣지 생성\n",
    "df['stock_list'] = split_and_clean(df['stock'])\n",
    "# (수정) 이름 충돌 방지를 위해 필요한 컬럼만 먼저 선택\n",
    "news_to_stock_edges = df[['crawled_news_id', 'stock_list']] \\\n",
    "    .explode('stock_list') \\\n",
    "    .rename(columns={'stock_list': 'stock'}) \\\n",
    "    .dropna()\n",
    "\n",
    "print(\"--- [1. 엣지 전처리 완료] ---\")\n",
    "print(f\"뉴스-키워드 엣지 수: {len(news_to_keyword_edges)}\")\n",
    "print(f\"뉴스-종목 엣지 수: {len(news_to_stock_edges)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd8490b9579d5fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T04:57:59.380726Z",
     "start_time": "2025-11-13T04:55:35.543042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2. 노드 정의 완료] ---\n",
      "뉴스 노드 수: 7543\n",
      "키워드 노드 수: 4793\n",
      "종목 노드 수: 562\n",
      "\n",
      "--- [2. 특징 생성 시작] ---\n",
      "  (A-1) 'news' 노드: Title 임베딩 중... (시간 소요)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541621541b5345b7ab2d73fcdc6a62f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dobi\\Desktop\\study\\DataPipeline\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dobi\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea745c4e5454d69a9beb0cd6bfc66f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55aa8c5dd3d4b48bd71bae72d2fc1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a3d63030284295847ddf993c4e8309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496b17926a104994b18e824a25d27ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb9b4a4dd8f402aac9eeee33f92b413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a081309991a401ba749b2446ec3f9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9cd13faf124e388e901f452e23fce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6f0da6b27d4287922dce14faee921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49132cd821a84682945004d0dd04b9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f175b38975564c3da8f8495d60b07617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (A-2) 'news' 노드: PubDate 스케일링 중...\n",
      "--- [2. 특징 생성 완료] ---\n",
      "뉴스 특징 벡터 차원: torch.Size([7543, 385])\n",
      "키워드 특징 벡터 차원: torch.Size([4793])\n",
      "종목 특징 벡터 차원: torch.Size([562])\n"
     ]
    }
   ],
   "source": [
    "## 2단계: 노드(Node) 및 특징(Feature) 생성\n",
    "# 목표: 3가지 노드(news, keyword, stock)를 정의하고, 숫자 벡터(특징)로 변환\n",
    "\n",
    "# 1. 고유 노드 및 매핑 생성\n",
    "# (중요) GNN은 0부터 시작하는 정수 인덱스를 사용합니다.\n",
    "# 원본 ID(crawled_news_id, '삼성전자') -> GNN용 ID(0, 1, 2...)로 변환\n",
    "\n",
    "# 뉴스 노드\n",
    "# 'crawled_news_id'를 GNN 인덱스(0 ~ len(df)-1)에 매핑\n",
    "news_id_map = {news_id: i for i, news_id in enumerate(df['crawled_news_id'])}\n",
    "\n",
    "# 키워드 노드\n",
    "unique_keywords = news_to_keyword_edges['keyword'].unique()\n",
    "keyword_map = {keyword: i for i, keyword in enumerate(unique_keywords)}\n",
    "\n",
    "# 종목 노드\n",
    "unique_stocks = news_to_stock_edges['stock'].unique()\n",
    "stock_map = {stock: i for i, stock in enumerate(unique_stocks)}\n",
    "\n",
    "print(\"--- [2. 노드 정의 완료] ---\")\n",
    "print(f\"뉴스 노드 수: {len(news_id_map)}\")\n",
    "print(f\"키워드 노드 수: {len(keyword_map)}\")\n",
    "print(f\"종목 노드 수: {len(stock_map)}\\n\")\n",
    "\n",
    "# 2. 노드 특징(Feature) 생성\n",
    "print(\"--- [2. 특징 생성 시작] ---\")\n",
    "\n",
    "# (A) 'news' 노드 특징: (Title Embedding + Scaled PubDate)\n",
    "# Title 임베딩 (SBERT)\n",
    "print(\"  (A-1) 'news' 노드: Title 임베딩 중... (시간 소요)\")\n",
    "sbert_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "# 'df'의 순서가 'news_id_map'의 0~N 순서와 동일하다고 가정하고 진행\n",
    "title_embeddings = sbert_model.encode(df['title'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# PubDate (최신성)\n",
    "print(\"  (A-2) 'news' 노드: PubDate 스케일링 중...\")\n",
    "# 날짜를 숫자로 변환 (Unix timestamp)\n",
    "pub_date_numeric = pd.to_datetime(df['pub_date']).astype('int64').values.reshape(-1, 1)\n",
    "# StandardScaler로 정규화 (평균 0, 분산 1)\n",
    "scaler = StandardScaler()\n",
    "pub_date_scaled = scaler.fit_transform(pub_date_numeric)\n",
    "\n",
    "# Title 임베딩과 날짜 특징 결합\n",
    "news_features = np.hstack([title_embeddings, pub_date_scaled])\n",
    "news_feat_tensor = torch.tensor(news_features, dtype=torch.float)\n",
    "news_feat_dim = news_features.shape[1] # GNN 모델에 전달할 차원 수\n",
    "\n",
    "# (B) 'keyword' 노드 특징: 고유 ID\n",
    "# 'keyword' 자체는 특징이 없으므로, GNN이 스스로 학습할 수 있도록\n",
    "# Embedding 레이어를 사용할 것입니다.\n",
    "# 여기서는 0부터 N-1까지의 인덱스를 특징으로 전달합니다.\n",
    "keyword_feat_tensor = torch.arange(len(unique_keywords))\n",
    "\n",
    "# (C) 'stock' 노드 특징: 고유 ID\n",
    "# 'keyword'와 동일하게 Embedding 레이어 사용\n",
    "stock_feat_tensor = torch.arange(len(unique_stocks))\n",
    "\n",
    "print(\"--- [2. 특징 생성 완료] ---\")\n",
    "print(f\"뉴스 특징 벡터 차원: {news_feat_tensor.shape}\")\n",
    "print(f\"키워드 특징 벡터 차원: {keyword_feat_tensor.shape}\")\n",
    "print(f\"종목 특징 벡터 차원: {stock_feat_tensor.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249fbce3df1d929c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T04:58:07.177684Z",
     "start_time": "2025-11-13T04:58:07.133238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [3. 그래프 생성 완료] ---\n",
      "HeteroData 객체:\n",
      "HeteroData(\n",
      "  news={ x=[7543, 385] },\n",
      "  keyword={ x=[4793] },\n",
      "  stock={ x=[562] },\n",
      "  (news, links_to, keyword)={ edge_index=[2, 75379] },\n",
      "  (news, mentions, stock)={ edge_index=[2, 10953] },\n",
      "  (keyword, rev_links_to, news)={ edge_index=[2, 75379] },\n",
      "  (stock, rev_mentions, news)={ edge_index=[2, 10953] }\n",
      ")\n",
      "\n",
      "그래프 엣지 타입: [('news', 'links_to', 'keyword'), ('news', 'mentions', 'stock'), ('keyword', 'rev_links_to', 'news'), ('stock', 'rev_mentions', 'news')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16400\\3366499819.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  data['news', 'links_to', 'keyword'].edge_index = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "## 3단계: 그래프(Graph) 생성\n",
    "# 목표: 1, 2단계의 결과를 PyTorch Geometric의 'HeteroData' 객체에 통합\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# 1. 노드 특징 할당\n",
    "data['news'].x = news_feat_tensor\n",
    "data['keyword'].x = keyword_feat_tensor\n",
    "data['stock'].x = stock_feat_tensor\n",
    "\n",
    "# 2. 엣지 인덱스 생성 및 할당\n",
    "# (뉴스 -> 키워드)\n",
    "src_news_kw = news_to_keyword_edges['crawled_news_id'].map(news_id_map).values\n",
    "dst_keyword = news_to_keyword_edges['keyword'].map(keyword_map).values\n",
    "data['news', 'links_to', 'keyword'].edge_index = torch.tensor(\n",
    "    [src_news_kw, dst_keyword], dtype=torch.long\n",
    ")\n",
    "\n",
    "# (뉴스 -> 종목)\n",
    "src_news_st = news_to_stock_edges['crawled_news_id'].map(news_id_map).values\n",
    "dst_stock = news_to_stock_edges['stock'].map(stock_map).values\n",
    "data['news', 'mentions', 'stock'].edge_index = torch.tensor(\n",
    "    [src_news_st, dst_stock], dtype=torch.long\n",
    ")\n",
    "\n",
    "# 3. 양방향 그래프로 변환\n",
    "# GNN은 메시지 패싱을 위해 양방향 엣지가 있을 때 학습이 잘 됩니다.\n",
    "# (news -> keyword) 뿐만 아니라 (keyword -> news) 엣지도 추가합니다.\n",
    "data = ToUndirected()(data)\n",
    "\n",
    "print(\"--- [3. 그래프 생성 완료] ---\")\n",
    "print(f\"HeteroData 객체:\\n{data}\\n\")\n",
    "print(f\"그래프 엣지 타입: {data.edge_types}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806a181fcd943e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T05:02:55.564165Z",
     "start_time": "2025-11-13T05:02:53.557681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [4. GNN 훈련 시작] ---\n",
      "사용 디바이스: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16400\\2162690416.py:162: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  return float(loss)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.9648, Val AUC: 0.7693\n",
      "Epoch: 020, Loss: 0.7590, Val AUC: 0.8215\n",
      "Epoch: 030, Loss: 0.6131, Val AUC: 0.8466\n",
      "Epoch: 040, Loss: 0.5093, Val AUC: 0.8589\n",
      "Epoch: 050, Loss: 0.4333, Val AUC: 0.8618\n",
      "Epoch: 060, Loss: 0.3805, Val AUC: 0.8645\n",
      "Epoch: 070, Loss: 0.3288, Val AUC: 0.8684\n",
      "Epoch: 080, Loss: 0.2837, Val AUC: 0.8718\n",
      "Epoch: 090, Loss: 0.2516, Val AUC: 0.8725\n",
      "Epoch: 100, Loss: 2.5061, Val AUC: 0.8728\n",
      "\n",
      "훈련 완료! 최고 검증 AUC: 0.8763\n"
     ]
    }
   ],
   "source": [
    "## 4단계: GNN 모델 설계 및 훈련 (수정)\n",
    "# 목표: '링크 예측' 태스크로 GNN을 훈련시켜 '연관성'을 학습\n",
    "\n",
    "# (수정) to_hetero 대신 HeteroConv를 임포트합니다.\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, HeteroConv\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- GNN 모델 정의 ---\n",
    "# 1. 인코더 (Encoder): 노드를 임베딩 벡터로 요약\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    # (수정) __init__에서 metadata가 더 이상 필요하지 않습니다.\n",
    "    def __init__(self, hidden_dim, out_dim, news_feat_dim, num_keywords, num_stocks):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 'keyword'와 'stock'은 특징이 없으므로(ID뿐), 학습 가능한 Embedding 레이어 생성\n",
    "        self.keyword_emb = torch.nn.Embedding(num_keywords, hidden_dim)\n",
    "        self.stock_emb = torch.nn.Embedding(num_stocks, hidden_dim)\n",
    "        \n",
    "        # 'news'는 특징이 있으므로(SBERT+Date), Linear 레이어로 차원 통일\n",
    "        self.news_lin = torch.nn.Linear(news_feat_dim, hidden_dim)\n",
    "        \n",
    "        # (수정) to_hetero 대신 HeteroConv를 사용합니다.\n",
    "        # HeteroConv는 각 엣지 타입별로 사용할 GNN 레이어를 명시적으로 정의합니다.\n",
    "        \n",
    "        # Layer 1: 입력 -> hidden_dim\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('news', 'links_to', 'keyword'): SAGEConv(-1, hidden_dim),\n",
    "            ('keyword', 'rev_links_to', 'news'): SAGEConv(-1, hidden_dim),\n",
    "            ('news', 'mentions', 'stock'): SAGEConv(-1, hidden_dim),\n",
    "            ('stock', 'rev_mentions', 'news'): SAGEConv(-1, hidden_dim),\n",
    "        }, aggr='sum')\n",
    "\n",
    "        # Layer 2: hidden_dim -> out_dim\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('news', 'links_to', 'keyword'): SAGEConv(-1, out_dim),\n",
    "            ('keyword', 'rev_links_to', 'news'): SAGEConv(-1, out_dim),\n",
    "            ('news', 'mentions', 'stock'): SAGEConv(-1, out_dim),\n",
    "            ('stock', 'rev_mentions', 'news'): SAGEConv(-1, out_dim),\n",
    "        }, aggr='sum')\n",
    "\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # 1. 초기 특징 변환 (Embedding / Linear)\n",
    "        x_dict = {\n",
    "            'news': self.news_lin(x_dict['news']).relu(), # ReLU 추가\n",
    "            'keyword': self.keyword_emb(x_dict['keyword']),\n",
    "            'stock': self.stock_emb(x_dict['stock'])\n",
    "        }\n",
    "        \n",
    "        # 2. GNN 레이어 (HeteroConv는 to_hetero 없이 바로 사용)\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        \n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        \n",
    "        return x_dict # 최종 임베딩 딕셔너리\n",
    "\n",
    "# 2. 디코더 (Decoder): 두 노드 임베딩으로 '링크' 여부 예측\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # 두 임베딩을 받아 1개의 값(링크 확률)으로 변환\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.lin2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        z = torch.cat([z_src, z_dst], dim=-1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "# 3. 전체 모델 (Encoder + Decoder)\n",
    "class Model(torch.nn.Module):\n",
    "    # (수정) __init__에서 metadata가 더 이상 필요하지 않습니다.\n",
    "    def __init__(self, hidden_dim, out_dim, news_feat_dim, num_keywords, num_stocks):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(\n",
    "            hidden_dim, out_dim, news_feat_dim, num_keywords, num_stocks\n",
    "        )\n",
    "        # 2가지 엣지(news-keyword, news-stock)를 예측할 디코더\n",
    "        self.decoders = torch.nn.ModuleDict({\n",
    "            'links_to': EdgeDecoder(out_dim),\n",
    "            'mentions': EdgeDecoder(out_dim),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index_dict):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict) # 최종 임베딩\n",
    "        \n",
    "        preds = {}\n",
    "        for edge_type, edge_label_index in edge_label_index_dict.items():\n",
    "            src_type, rel_type, dst_type = edge_type\n",
    "            \n",
    "            z_src = z_dict[src_type][edge_label_index[0]]\n",
    "            z_dst = z_dict[dst_type][edge_label_index[1]]\n",
    "            \n",
    "            preds[edge_type] = self.decoders[rel_type](z_src, z_dst)\n",
    "            \n",
    "        return preds\n",
    "\n",
    "# --- 훈련 준비 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"--- [4. GNN 훈련 시작] ---\\n사용 디바이스: {device}\\n\")\n",
    "\n",
    "# 1. 훈련/검증/테스트 데이터 분할 (링크 예측용)\n",
    "# (주의) data 객체를 변환하므로, 이 분할은 'data' 객체에 대해 한 번만 실행해야 합니다.\n",
    "# 만약 코드를 여러 번 실행했다면, '3단계: 그래프 생성' 부터 다시 실행하는 것이 안전합니다.\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,  # 10% 검증\n",
    "    num_test=0.1, # 10% 테스트\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=True, # (중요) '없는 엣지'도 샘플링\n",
    "    edge_types=[('news', 'links_to', 'keyword'), ('news', 'mentions', 'stock')],\n",
    "    rev_edge_types=[('keyword', 'rev_links_to', 'news'), ('stock', 'rev_mentions', 'news')],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# 2. 모델, 옵티마이저, 손실함수 초기화\n",
    "HIDDEN_DIM = 64\n",
    "OUT_DIM = 32 # 최종 임베딩 차원\n",
    "\n",
    "model = Model(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    out_dim=OUT_DIM,\n",
    "    news_feat_dim=news_feat_dim,\n",
    "    num_keywords=len(unique_keywords),\n",
    "    num_stocks=len(unique_stocks)\n",
    "    # (수정) metadata 인자 제거\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "# 긍정/부정 링크(엣지)를 분류하는 이진 분류 문제\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# --- 훈련 함수 ---\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 훈련용 엣지(pos/neg)\n",
    "    edge_label_index_dict = {\n",
    "        ('news', 'links_to', 'keyword'): data['news', 'links_to', 'keyword'].edge_label_index,\n",
    "        ('news', 'mentions', 'stock'): data['news', 'mentions', 'stock'].edge_label_index\n",
    "    }\n",
    "    \n",
    "    # 모델 예측\n",
    "    preds_dict = model(data.x_dict, data.edge_index_dict, edge_label_index_dict)\n",
    "    \n",
    "    # 정답 레이블\n",
    "    labels_dict = {\n",
    "        ('news', 'links_to', 'keyword'): data['news', 'links_to', 'keyword'].edge_label,\n",
    "        ('news', 'mentions', 'stock'): data['news', 'mentions', 'stock'].edge_label\n",
    "    }\n",
    "\n",
    "    # 2가지 엣지 타입의 손실을 합산\n",
    "    loss = 0\n",
    "    for edge_type in preds_dict:\n",
    "        loss += criterion(preds_dict[edge_type], labels_dict[edge_type].float())\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "# --- 검증 함수 ---\n",
    "@torch.no_grad()\n",
    "def evaluate(data):\n",
    "    model.eval()\n",
    "    \n",
    "    edge_label_index_dict = {\n",
    "        ('news', 'links_to', 'keyword'): data['news', 'links_to', 'keyword'].edge_label_index,\n",
    "        ('news', 'mentions', 'stock'): data['news', 'mentions', 'stock'].edge_label_index\n",
    "    }\n",
    "    preds_dict = model(data.x_dict, data.edge_index_dict, edge_label_index_dict)\n",
    "    \n",
    "    labels_dict = {\n",
    "        ('news', 'links_to', 'keyword'): data['news', 'links_to', 'keyword'].edge_label,\n",
    "        ('news', 'mentions', 'stock'): data['news', 'mentions', 'stock'].edge_label\n",
    "    }\n",
    "    \n",
    "    total_auc = 0\n",
    "    for edge_type in preds_dict:\n",
    "        preds = preds_dict[edge_type].sigmoid().cpu().numpy()\n",
    "        labels = labels_dict[edge_type].cpu().numpy()\n",
    "        total_auc += roc_auc_score(labels, preds)\n",
    "        \n",
    "    return total_auc / len(preds_dict) # 평균 AUC\n",
    "\n",
    "# --- 훈련 루프 실행 ---\n",
    "train_data, val_data = train_data.to(device), val_data.to(device)\n",
    "best_val_auc = 0\n",
    "\n",
    "for epoch in range(1, 101): # 100 에포크\n",
    "    loss = train(train_data)\n",
    "    val_auc = evaluate(val_data)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        # (선택) 최고 성능 모델 저장\n",
    "        # torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print(f\"\\n훈련 완료! 최고 검증 AUC: {best_val_auc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c012643cff3db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T05:03:08.344205Z",
     "start_time": "2025-11-13T05:03:08.303874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [5. 최종 임베딩 추출] ---\n",
      "임베딩 추출 성공!\n",
      "  - 'keyword' 임베딩 크기: [4793, 32]\n",
      "  - 'news' 임베딩 크기: [7543, 32]\n",
      "  - 'stock' 임베딩 크기: [562, 32]\n",
      "\n",
      "--- [작업 완료] ---\n",
      "이제 'final_embeddings_cpu' 딕셔너리의 벡터들을 Vector DB에 저장할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "## 5단계: 최종 임베딩 추출\n",
    "# 목표: 훈련된 GNN Encoder를 사용하여 모든 노드의 최종 임베딩 벡터 추출\n",
    "\n",
    "print(\"--- [5. 최종 임베딩 추출] ---\")\n",
    "\n",
    "# (중요) 훈련 시 사용한 'train_data'가 아닌,\n",
    "# 모든 엣지 정보가 포함된 원본 'data' 객체를 사용합니다.\n",
    "data = data.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # model.encoder만 호출하여 GNN을 통과한 최종 노드 임베딩을 얻습니다.\n",
    "    final_embeddings = model.encoder(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"임베딩 추출 성공!\")\n",
    "for node_type, embedding_tensor in final_embeddings.items():\n",
    "    print(f\"  - '{node_type}' 임베딩 크기: {list(embedding_tensor.shape)}\")\n",
    "\n",
    "# CPU로 이동\n",
    "final_embeddings_cpu = {\n",
    "    key: tensor.cpu().numpy() for key, tensor in final_embeddings.items()\n",
    "}\n",
    "# 'final_embeddings' 딕셔너리가 최종 산출물입니다.\n",
    "# \n",
    "# final_embeddings_cpu['news'] -> (7543, 32) 크기의 Numpy 배열\n",
    "# final_embeddings_cpu['keyword'] -> (len(unique_keywords), 32) 크기의 Numpy 배열\n",
    "# final_embeddings_cpu['stock'] -> (len(unique_stocks), 32) 크기의 Numpy 배열\n",
    "#\n",
    "# 이 벡터들을 Vector DB에 저장하여 유사도 검색에 활용할 수 있습니다.\n",
    "# (예: 'AI' 키워드 벡터와 가장 가까운 'stock' 벡터 찾기)\n",
    "\n",
    "print(\"\\n--- [작업 완료] ---\")\n",
    "print(\"이제 'final_embeddings_cpu' 딕셔너리의 벡터들을 Vector DB에 저장할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145e3ee756011629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T05:14:15.301568Z",
     "start_time": "2025-11-13T05:14:15.275986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [0. 전체 탐색 대상 구축 시작] ---\n",
      "총 5355개 노드 (키워드 4793 + 유효 종목 562)의 임베딩 행렬 구축 완료.\n",
      "소요 시간: 0.00초\n",
      "\n",
      "==================================================\n",
      "🔍 [작업 1] 랜덤 키워드 10개에 대한 TOP 20 유사 노드\n",
      "==================================================\n",
      "\n",
      "--- [1- 1] 쿼리: '인기' (키워드) ---\n",
      "   1위. 배우 (키워드) (유사도: 0.9783)\n",
      "   2위. 드라마 (키워드) (유사도: 0.9782)\n",
      "   3위. 시청자 (키워드) (유사도: 0.9778)\n",
      "   4위. 연기 (키워드) (유사도: 0.9763)\n",
      "   5위. 연애 (키워드) (유사도: 0.9751)\n",
      "   6위. 영화 (키워드) (유사도: 0.9729)\n",
      "   7위. 조용필 (키워드) (유사도: 0.9663)\n",
      "   8위. 숙소 (키워드) (유사도: 0.9638)\n",
      "   9위. 발매 (키워드) (유사도: 0.9634)\n",
      "  10위. 기사 (키워드) (유사도: 0.9627)\n",
      "  11위. 캐스팅 (키워드) (유사도: 0.9624)\n",
      "  12위. 인간 (키워드) (유사도: 0.9624)\n",
      "  13위. 부작 (키워드) (유사도: 0.9599)\n",
      "  14위. 미리 (키워드) (유사도: 0.9590)\n",
      "  15위. 정말 (키워드) (유사도: 0.9589)\n",
      "  16위. 관객 (키워드) (유사도: 0.9582)\n",
      "  17위. 주인공 (키워드) (유사도: 0.9570)\n",
      "  18위. 재회 (키워드) (유사도: 0.9566)\n",
      "  19위. 셰프 (키워드) (유사도: 0.9565)\n",
      "  20위. 지영 (키워드) (유사도: 0.9563)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 2] 쿼리: '야외' (키워드) ---\n",
      "   1위. 규범 (키워드) (유사도: 0.9531)\n",
      "   2위. 폭우 (키워드) (유사도: 0.9482)\n",
      "   3위. 표적 (키워드) (유사도: 0.9455)\n",
      "   4위. 관찰 (키워드) (유사도: 0.9450)\n",
      "   5위. 미숙 (키워드) (유사도: 0.9450)\n",
      "   6위. 신부 (키워드) (유사도: 0.9393)\n",
      "   7위. 스탑 (키워드) (유사도: 0.9383)\n",
      "   8위. 특위 (키워드) (유사도: 0.9377)\n",
      "   9위. 종결 (키워드) (유사도: 0.9349)\n",
      "  10위. 순방 (키워드) (유사도: 0.9338)\n",
      "  11위. 홀로 (키워드) (유사도: 0.9323)\n",
      "  12위. 학점 (키워드) (유사도: 0.9320)\n",
      "  13위. 정성 (키워드) (유사도: 0.9302)\n",
      "  14위. 정작 (키워드) (유사도: 0.9253)\n",
      "  15위. 공작 (키워드) (유사도: 0.9246)\n",
      "  16위. 이탈 (키워드) (유사도: 0.9245)\n",
      "  17위. 귀국 (키워드) (유사도: 0.9243)\n",
      "  18위. 제보 (키워드) (유사도: 0.9240)\n",
      "  19위. 이하 (키워드) (유사도: 0.9224)\n",
      "  20위. 청산 (키워드) (유사도: 0.9223)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 3] 쿼리: '포스트' (키워드) ---\n",
      "   1위. 순위 (키워드) (유사도: 0.9689)\n",
      "   2위. 향기 (키워드) (유사도: 0.9623)\n",
      "   3위. 일보 (키워드) (유사도: 0.9540)\n",
      "   4위. 사가 (키워드) (유사도: 0.9534)\n",
      "   5위. 폐업 (키워드) (유사도: 0.9511)\n",
      "   6위. 전투 (키워드) (유사도: 0.9422)\n",
      "   7위. 출처 (키워드) (유사도: 0.9419)\n",
      "   8위. 아이템 (키워드) (유사도: 0.9358)\n",
      "   9위. 리스트 (키워드) (유사도: 0.9346)\n",
      "  10위. 대만 (키워드) (유사도: 0.9326)\n",
      "  11위. 로그인 (키워드) (유사도: 0.9326)\n",
      "  12위. 진출 (키워드) (유사도: 0.9317)\n",
      "  13위. 상영 (키워드) (유사도: 0.9309)\n",
      "  14위. 랜드 (키워드) (유사도: 0.9298)\n",
      "  15위. 바디 (키워드) (유사도: 0.9295)\n",
      "  16위. 감상 (키워드) (유사도: 0.9271)\n",
      "  17위. 구매 (키워드) (유사도: 0.9268)\n",
      "  18위. 압축 (키워드) (유사도: 0.9256)\n",
      "  19위. 이유 (키워드) (유사도: 0.9234)\n",
      "  20위. 인간 (키워드) (유사도: 0.9229)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 4] 쿼리: '초점' (키워드) ---\n",
      "   1위. 보더 (키워드) (유사도: 0.9563)\n",
      "   2위. 안고 (키워드) (유사도: 0.9551)\n",
      "   3위. 수백 (키워드) (유사도: 0.9505)\n",
      "   4위. 도리 (키워드) (유사도: 0.9377)\n",
      "   5위. 명성 (키워드) (유사도: 0.9298)\n",
      "   6위. 리기 (키워드) (유사도: 0.9207)\n",
      "   7위. 려고 (키워드) (유사도: 0.9099)\n",
      "   8위. 당황 (키워드) (유사도: 0.9092)\n",
      "   9위. 지형 (키워드) (유사도: 0.9070)\n",
      "  10위. 주저 (키워드) (유사도: 0.9045)\n",
      "  11위. 막상 (키워드) (유사도: 0.8934)\n",
      "  12위. 가의 (키워드) (유사도: 0.8905)\n",
      "  13위. 아시 (키워드) (유사도: 0.8899)\n",
      "  14위. 달이 (키워드) (유사도: 0.8883)\n",
      "  15위. 계산 (키워드) (유사도: 0.8875)\n",
      "  16위. 금방 (키워드) (유사도: 0.8864)\n",
      "  17위. 개시 (키워드) (유사도: 0.8856)\n",
      "  18위. 자로 (키워드) (유사도: 0.8849)\n",
      "  19위. 보기 (키워드) (유사도: 0.8848)\n",
      "  20위. 래야 (키워드) (유사도: 0.8819)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 5] 쿼리: '경청' (키워드) ---\n",
      "   1위. 선언 (키워드) (유사도: 0.9796)\n",
      "   2위. 음성 (키워드) (유사도: 0.9685)\n",
      "   3위. 파출소 (키워드) (유사도: 0.9666)\n",
      "   4위. 수용 (키워드) (유사도: 0.9648)\n",
      "   5위. 박수 (키워드) (유사도: 0.9627)\n",
      "   6위. 전현희 (키워드) (유사도: 0.9617)\n",
      "   7위. 사과 (키워드) (유사도: 0.9586)\n",
      "   8위. 아래 (키워드) (유사도: 0.9577)\n",
      "   9위. 도발 (키워드) (유사도: 0.9568)\n",
      "  10위. 집권 (키워드) (유사도: 0.9568)\n",
      "  11위. 진실 (키워드) (유사도: 0.9561)\n",
      "  12위. 겨냥 (키워드) (유사도: 0.9561)\n",
      "  13위. 구치소 (키워드) (유사도: 0.9549)\n",
      "  14위. 법적 (키워드) (유사도: 0.9546)\n",
      "  15위. 무제한 (키워드) (유사도: 0.9544)\n",
      "  16위. 소식 (키워드) (유사도: 0.9534)\n",
      "  17위. 피의자 (키워드) (유사도: 0.9532)\n",
      "  18위. 찬성 (키워드) (유사도: 0.9530)\n",
      "  19위. 지지자 (키워드) (유사도: 0.9529)\n",
      "  20위. 공판 (키워드) (유사도: 0.9527)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 6] 쿼리: '야권' (키워드) ---\n",
      "   1위. 수장 (키워드) (유사도: 0.9772)\n",
      "   2위. 질타 (키워드) (유사도: 0.9732)\n",
      "   3위. 정무수석 (키워드) (유사도: 0.9731)\n",
      "   4위. 구속영장 (키워드) (유사도: 0.9715)\n",
      "   5위. 윤희 (키워드) (유사도: 0.9691)\n",
      "   6위. 손수조 (키워드) (유사도: 0.9688)\n",
      "   7위. 동대문구 (키워드) (유사도: 0.9660)\n",
      "   8위. 진영 (키워드) (유사도: 0.9654)\n",
      "   9위. 송구 (키워드) (유사도: 0.9637)\n",
      "  10위. 국가안보실 (키워드) (유사도: 0.9634)\n",
      "  11위. 김남준 (키워드) (유사도: 0.9632)\n",
      "  12위. 비쟁점 (키워드) (유사도: 0.9612)\n",
      "  13위. 방위 (키워드) (유사도: 0.9608)\n",
      "  14위. 비핵화 (키워드) (유사도: 0.9604)\n",
      "  15위. 수사권 (키워드) (유사도: 0.9604)\n",
      "  16위. 서관 (키워드) (유사도: 0.9597)\n",
      "  17위. 구두 (키워드) (유사도: 0.9596)\n",
      "  18위. 보완 (키워드) (유사도: 0.9586)\n",
      "  19위. 후속 (키워드) (유사도: 0.9580)\n",
      "  20위. 비서실 (키워드) (유사도: 0.9576)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 7] 쿼리: '처가' (키워드) ---\n",
      "   1위. 부탁 (키워드) (유사도: 0.9817)\n",
      "   2위. 연예인 (키워드) (유사도: 0.9747)\n",
      "   3위. 박지현 (키워드) (유사도: 0.9705)\n",
      "   4위. 세력 (키워드) (유사도: 0.9696)\n",
      "   5위. 지도 (키워드) (유사도: 0.9629)\n",
      "   6위. 일기 (키워드) (유사도: 0.9624)\n",
      "   7위. 일화 (키워드) (유사도: 0.9606)\n",
      "   8위. 대변 (키워드) (유사도: 0.9604)\n",
      "   9위. 상연 (키워드) (유사도: 0.9589)\n",
      "  10위. 종일 (키워드) (유사도: 0.9538)\n",
      "  11위. 동시 (키워드) (유사도: 0.9526)\n",
      "  12위. 증명 (키워드) (유사도: 0.9499)\n",
      "  13위. 매체 (키워드) (유사도: 0.9482)\n",
      "  14위. 백합 (키워드) (유사도: 0.9480)\n",
      "  15위. 적지 (키워드) (유사도: 0.9475)\n",
      "  16위. 평양 (키워드) (유사도: 0.9475)\n",
      "  17위. 복무 (키워드) (유사도: 0.9466)\n",
      "  18위. 김민수 (키워드) (유사도: 0.9464)\n",
      "  19위. 영수 (키워드) (유사도: 0.9446)\n",
      "  20위. 영식 (키워드) (유사도: 0.9445)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 8] 쿼리: '총회' (키워드) ---\n",
      "   1위. 해제 (키워드) (유사도: 0.9721)\n",
      "   2위. 관련 (키워드) (유사도: 0.9720)\n",
      "   3위. 유엔 (키워드) (유사도: 0.9713)\n",
      "   4위. 상황 (키워드) (유사도: 0.9694)\n",
      "   5위. 자살 (키워드) (유사도: 0.9693)\n",
      "   6위. 매뉴얼 (키워드) (유사도: 0.9686)\n",
      "   7위. 참사 (키워드) (유사도: 0.9684)\n",
      "   8위. 출마 (키워드) (유사도: 0.9684)\n",
      "   9위. 파악 (키워드) (유사도: 0.9659)\n",
      "  10위. 정상화 (키워드) (유사도: 0.9651)\n",
      "  11위. 청구 (키워드) (유사도: 0.9649)\n",
      "  12위. 당부 (키워드) (유사도: 0.9647)\n",
      "  13위. 협조 (키워드) (유사도: 0.9617)\n",
      "  14위. 공세 (키워드) (유사도: 0.9616)\n",
      "  15위. 장병 (키워드) (유사도: 0.9613)\n",
      "  16위. 개편안 (키워드) (유사도: 0.9602)\n",
      "  17위. 요구 (키워드) (유사도: 0.9599)\n",
      "  18위. 정당 (키워드) (유사도: 0.9597)\n",
      "  19위. 귀성 (키워드) (유사도: 0.9588)\n",
      "  20위. 보고 (키워드) (유사도: 0.9587)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 9] 쿼리: '작품' (키워드) ---\n",
      "   1위. 연애 (키워드) (유사도: 0.9748)\n",
      "   2위. 셰프 (키워드) (유사도: 0.9717)\n",
      "   3위. 드라마 (키워드) (유사도: 0.9700)\n",
      "   4위. 연기 (키워드) (유사도: 0.9647)\n",
      "   5위. 음악 (키워드) (유사도: 0.9646)\n",
      "   6위. 명품 (키워드) (유사도: 0.9636)\n",
      "   7위. 현지 (키워드) (유사도: 0.9603)\n",
      "   8위. 무대 (키워드) (유사도: 0.9593)\n",
      "   9위. 투어 (키워드) (유사도: 0.9589)\n",
      "  10위. 관객 (키워드) (유사도: 0.9587)\n",
      "  11위. 영화 (키워드) (유사도: 0.9581)\n",
      "  12위. 인기 (키워드) (유사도: 0.9558)\n",
      "  13위. 사진 (키워드) (유사도: 0.9530)\n",
      "  14위. 케이 (키워드) (유사도: 0.9510)\n",
      "  15위. 미술관 (키워드) (유사도: 0.9508)\n",
      "  16위. 인간 (키워드) (유사도: 0.9508)\n",
      "  17위. 배우 (키워드) (유사도: 0.9507)\n",
      "  18위. 작가 (키워드) (유사도: 0.9474)\n",
      "  19위. 개월 (키워드) (유사도: 0.9459)\n",
      "  20위. 증상 (키워드) (유사도: 0.9451)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-10] 쿼리: '중요' (키워드) ---\n",
      "   1위. 증거 (키워드) (유사도: 0.9762)\n",
      "   2위. 마무리 (키워드) (유사도: 0.9751)\n",
      "   3위. 국무회의 (키워드) (유사도: 0.9721)\n",
      "   4위. 구속적부심 (키워드) (유사도: 0.9709)\n",
      "   5위. 정치자금 (키워드) (유사도: 0.9705)\n",
      "   6위. 최대한 (키워드) (유사도: 0.9695)\n",
      "   7위. 형사소송법 (키워드) (유사도: 0.9691)\n",
      "   8위. 대구시 (키워드) (유사도: 0.9685)\n",
      "   9위. 중인 (키워드) (유사도: 0.9656)\n",
      "  10위. 청과 (키워드) (유사도: 0.9626)\n",
      "  11위. 명칭 (키워드) (유사도: 0.9586)\n",
      "  12위. 금품 (키워드) (유사도: 0.9584)\n",
      "  13위. 한반도 (키워드) (유사도: 0.9560)\n",
      "  14위. 도주 (키워드) (유사도: 0.9558)\n",
      "  15위. 소속 (키워드) (유사도: 0.9531)\n",
      "  16위. 지적도 (키워드) (유사도: 0.9527)\n",
      "  17위. 문구 (키워드) (유사도: 0.9524)\n",
      "  18위. 강요 (키워드) (유사도: 0.9512)\n",
      "  19위. 가중 (키워드) (유사도: 0.9512)\n",
      "  20위. 고위 (키워드) (유사도: 0.9509)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "==================================================\n",
      "📈 [작업 2] 랜덤 종목 10개에 대한 TOP 20 유사 노드\n",
      "==================================================\n",
      "\n",
      "--- [2- 1] 쿼리: '현대이지웰' (종목) ---\n",
      "   1위. HL D&I (종목) (유사도: 0.9945)\n",
      "   2위. 누보 (종목) (유사도: 0.9944)\n",
      "   3위. 대창 (종목) (유사도: 0.9933)\n",
      "   4위. JW중외제약 (종목) (유사도: 0.9931)\n",
      "   5위. 삼천당제약 (종목) (유사도: 0.9931)\n",
      "   6위. 남양유업 (종목) (유사도: 0.9924)\n",
      "   7위. 제일약품 (종목) (유사도: 0.9923)\n",
      "   8위. 올릭스 (종목) (유사도: 0.9922)\n",
      "   9위. 일동제약 (종목) (유사도: 0.9922)\n",
      "  10위. 알테오젠 (종목) (유사도: 0.9921)\n",
      "  11위. 동아에스티 (종목) (유사도: 0.9920)\n",
      "  12위. 위메이드맥스 (종목) (유사도: 0.9920)\n",
      "  13위. 노랑풍선 (종목) (유사도: 0.9919)\n",
      "  14위. NAVER (종목) (유사도: 0.9918)\n",
      "  15위. 동국제약 (종목) (유사도: 0.9914)\n",
      "  16위. 비에이치 (종목) (유사도: 0.9912)\n",
      "  17위. 인투셀 (종목) (유사도: 0.9908)\n",
      "  18위. 알에스오토메이션 (종목) (유사도: 0.9907)\n",
      "  19위. 아이엠 (종목) (유사도: 0.9907)\n",
      "  20위. 코스맥스 (종목) (유사도: 0.9907)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 2] 쿼리: '탈로스' (종목) ---\n",
      "   1위. 서한 (종목) (유사도: 0.9329)\n",
      "   2위. 유신 (종목) (유사도: 0.9013)\n",
      "   3위. 파수 (종목) (유사도: 0.9001)\n",
      "   4위. 대웅 (종목) (유사도: 0.8994)\n",
      "   5위. 카카오페이 (종목) (유사도: 0.8945)\n",
      "   6위. 러셀 (종목) (유사도: 0.8927)\n",
      "   7위. 도이치모터스 (종목) (유사도: 0.8843)\n",
      "   8위. 교보증권 (종목) (유사도: 0.8775)\n",
      "   9위. 대덕 (종목) (유사도: 0.8750)\n",
      "  10위. HMM (종목) (유사도: 0.8640)\n",
      "  11위. 서희건설 (종목) (유사도: 0.8575)\n",
      "  12위. 삼일 (종목) (유사도: 0.8572)\n",
      "  13위. 상보 (종목) (유사도: 0.8529)\n",
      "  14위. 희림 (종목) (유사도: 0.8511)\n",
      "  15위. 무학 (종목) (유사도: 0.8461)\n",
      "  16위. 율촌 (종목) (유사도: 0.8373)\n",
      "  17위. 에스코넥 (종목) (유사도: 0.8324)\n",
      "  18위. NEW (종목) (유사도: 0.8277)\n",
      "  19위. 엠브레인 (종목) (유사도: 0.8222)\n",
      "  20위. 코웨이 (종목) (유사도: 0.8187)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 3] 쿼리: '한글과컴퓨터' (종목) ---\n",
      "   1위. STX엔진 (종목) (유사도: 0.9958)\n",
      "   2위. SNT다이내믹스 (종목) (유사도: 0.9956)\n",
      "   3위. LG씨엔에스 (종목) (유사도: 0.9946)\n",
      "   4위. 엠앤씨솔루션 (종목) (유사도: 0.9945)\n",
      "   5위. SKC (종목) (유사도: 0.9935)\n",
      "   6위. 필옵틱스 (종목) (유사도: 0.9934)\n",
      "   7위. 에이디테크놀로지 (종목) (유사도: 0.9934)\n",
      "   8위. 우리기술투자 (종목) (유사도: 0.9929)\n",
      "   9위. 가온칩스 (종목) (유사도: 0.9927)\n",
      "  10위. 삼성전기 (종목) (유사도: 0.9922)\n",
      "  11위. 에스엠 (종목) (유사도: 0.9920)\n",
      "  12위. 솔브레인 (종목) (유사도: 0.9918)\n",
      "  13위. 아이티센글로벌 (종목) (유사도: 0.9913)\n",
      "  14위. 와이씨켐 (종목) (유사도: 0.9911)\n",
      "  15위. 동국제약 (종목) (유사도: 0.9908)\n",
      "  16위. 두산에너빌리티 (종목) (유사도: 0.9899)\n",
      "  17위. 현대차증권 (종목) (유사도: 0.9891)\n",
      "  18위. 피에스케이 (종목) (유사도: 0.9891)\n",
      "  19위. 한미반도체 (종목) (유사도: 0.9886)\n",
      "  20위. 삼성증권 (종목) (유사도: 0.9885)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 4] 쿼리: '딜리' (종목) ---\n",
      "   1위. 에이비엘바이오 (종목) (유사도: 0.9946)\n",
      "   2위. 쿠쿠홀딩스 (종목) (유사도: 0.9936)\n",
      "   3위. 현대엘리베이터 (종목) (유사도: 0.9936)\n",
      "   4위. 두산로보틱스 (종목) (유사도: 0.9925)\n",
      "   5위. 더존비즈온 (종목) (유사도: 0.9922)\n",
      "   6위. 지엔씨에너지 (종목) (유사도: 0.9920)\n",
      "   7위. 콜마홀딩스 (종목) (유사도: 0.9920)\n",
      "   8위. 에스엠 (종목) (유사도: 0.9917)\n",
      "   9위. 메리츠금융지주 (종목) (유사도: 0.9917)\n",
      "  10위. 광동제약 (종목) (유사도: 0.9916)\n",
      "  11위. 피에스케이 (종목) (유사도: 0.9916)\n",
      "  12위. 펩트론 (종목) (유사도: 0.9915)\n",
      "  13위. 하스 (종목) (유사도: 0.9914)\n",
      "  14위. 지아이이노베이션 (종목) (유사도: 0.9911)\n",
      "  15위. 노브랜드 (종목) (유사도: 0.9907)\n",
      "  16위. 계룡건설산업 (종목) (유사도: 0.9906)\n",
      "  17위. 하나제약 (종목) (유사도: 0.9905)\n",
      "  18위. 진에어 (종목) (유사도: 0.9903)\n",
      "  19위. 이지스레지던스리츠 (종목) (유사도: 0.9902)\n",
      "  20위. HD현대마린솔루션 (종목) (유사도: 0.9902)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 5] 쿼리: '태성' (종목) ---\n",
      "   1위. DSR (종목) (유사도: 0.9776)\n",
      "   2위. 대한전선 (종목) (유사도: 0.9770)\n",
      "   3위. 모나리자 (종목) (유사도: 0.9759)\n",
      "   4위. 현대제철 (종목) (유사도: 0.9753)\n",
      "   5위. 방림 (종목) (유사도: 0.9717)\n",
      "   6위. 천보 (종목) (유사도: 0.9713)\n",
      "   7위. 대한유화 (종목) (유사도: 0.9708)\n",
      "   8위. 한글과컴퓨터 (종목) (유사도: 0.9705)\n",
      "   9위. LIG넥스원 (종목) (유사도: 0.9696)\n",
      "  10위. SKC (종목) (유사도: 0.9688)\n",
      "  11위. STX엔진 (종목) (유사도: 0.9671)\n",
      "  12위. 엠앤씨솔루션 (종목) (유사도: 0.9665)\n",
      "  13위. SNT다이내믹스 (종목) (유사도: 0.9664)\n",
      "  14위. 녹십자 (종목) (유사도: 0.9662)\n",
      "  15위. LG씨엔에스 (종목) (유사도: 0.9660)\n",
      "  16위. 삼성전기 (종목) (유사도: 0.9648)\n",
      "  17위. 우리기술투자 (종목) (유사도: 0.9642)\n",
      "  18위. 서연 (종목) (유사도: 0.9638)\n",
      "  19위. 배럴 (종목) (유사도: 0.9638)\n",
      "  20위. 한국전력공사 (종목) (유사도: 0.9634)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 6] 쿼리: '엔씨소프트' (종목) ---\n",
      "   1위. 컴투스 (종목) (유사도: 0.9681)\n",
      "   2위. 한국가스공사 (종목) (유사도: 0.9485)\n",
      "   3위. LG화학 (종목) (유사도: 0.9430)\n",
      "   4위. 다올투자증권 (종목) (유사도: 0.9412)\n",
      "   5위. 제놀루션 (종목) (유사도: 0.9402)\n",
      "   6위. SK증권 (종목) (유사도: 0.9401)\n",
      "   7위. 현대홈쇼핑 (종목) (유사도: 0.9395)\n",
      "   8위. LG유플러스 (종목) (유사도: 0.9384)\n",
      "   9위. 넷마블 (종목) (유사도: 0.9377)\n",
      "  10위. 신스틸 (종목) (유사도: 0.9362)\n",
      "  11위. 동부건설 (종목) (유사도: 0.9360)\n",
      "  12위. 카카오뱅크 (종목) (유사도: 0.9356)\n",
      "  13위. HD한국조선해양 (종목) (유사도: 0.9344)\n",
      "  14위. 롯데케미칼 (종목) (유사도: 0.9320)\n",
      "  15위. 우리금융지주 (종목) (유사도: 0.9317)\n",
      "  16위. NH투자증권 (종목) (유사도: 0.9309)\n",
      "  17위. DMS (종목) (유사도: 0.9307)\n",
      "  18위. 유안타증권 (종목) (유사도: 0.9295)\n",
      "  19위. 웹젠 (종목) (유사도: 0.9294)\n",
      "  20위. 이월드 (종목) (유사도: 0.9282)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 7] 쿼리: '두산에너빌리티' (종목) ---\n",
      "   1위. 대웅제약 (종목) (유사도: 0.9952)\n",
      "   2위. 동국제약 (종목) (유사도: 0.9934)\n",
      "   3위. 삼천당제약 (종목) (유사도: 0.9933)\n",
      "   4위. 엠앤씨솔루션 (종목) (유사도: 0.9930)\n",
      "   5위. 에스엠 (종목) (유사도: 0.9929)\n",
      "   6위. 에이디테크놀로지 (종목) (유사도: 0.9929)\n",
      "   7위. 삼양식품 (종목) (유사도: 0.9924)\n",
      "   8위. 한국콜마 (종목) (유사도: 0.9922)\n",
      "   9위. 한화엔진 (종목) (유사도: 0.9920)\n",
      "  10위. NAVER (종목) (유사도: 0.9918)\n",
      "  11위. 흥국화재 (종목) (유사도: 0.9916)\n",
      "  12위. 제닉 (종목) (유사도: 0.9916)\n",
      "  13위. 아이엠 (종목) (유사도: 0.9911)\n",
      "  14위. 케이프 (종목) (유사도: 0.9908)\n",
      "  15위. 유한양행 (종목) (유사도: 0.9906)\n",
      "  16위. HD현대 (종목) (유사도: 0.9904)\n",
      "  17위. SNT다이내믹스 (종목) (유사도: 0.9901)\n",
      "  18위. 한글과컴퓨터 (종목) (유사도: 0.9899)\n",
      "  19위. 아모레퍼시픽 (종목) (유사도: 0.9898)\n",
      "  20위. 에스원 (종목) (유사도: 0.9897)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 8] 쿼리: '효성' (종목) ---\n",
      "   1위. 전방 (종목) (유사도: 0.9917)\n",
      "   2위. 한창 (종목) (유사도: 0.9830)\n",
      "   3위. 카카오 (종목) (유사도: 0.9816)\n",
      "   4위. 진영 (종목) (유사도: 0.9733)\n",
      "   5위. 도부 (종목) (유사도: 0.9727)\n",
      "   6위. 아하 (종목) (유사도: 0.9717)\n",
      "   7위. YTN (종목) (유사도: 0.9694)\n",
      "   8위. 진도 (종목) (유사도: 0.9685)\n",
      "   9위. 대원 (종목) (유사도: 0.9681)\n",
      "  10위. 대상 (종목) (유사도: 0.9653)\n",
      "  11위. KB금융 (종목) (유사도: 0.9640)\n",
      "  12위. 디오 (종목) (유사도: 0.9545)\n",
      "  13위. SBS (종목) (유사도: 0.9487)\n",
      "  14위. 성우 (종목) (유사도: 0.9449)\n",
      "  15위. 남성 (종목) (유사도: 0.9418)\n",
      "  16위. 대교 (종목) (유사도: 0.9293)\n",
      "  17위. 사람인 (종목) (유사도: 0.9282)\n",
      "  18위. 신원 (종목) (유사도: 0.9275)\n",
      "  19위. 나노 (종목) (유사도: 0.9255)\n",
      "  20위. 하이브 (종목) (유사도: 0.9211)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 9] 쿼리: 'NICE평가정보' (종목) ---\n",
      "   1위. KD (종목) (유사도: 0.9462)\n",
      "   2위. 호텔신라 (종목) (유사도: 0.9206)\n",
      "   3위. 영풍 (종목) (유사도: 0.9153)\n",
      "   4위. 부스타 (종목) (유사도: 0.9152)\n",
      "   5위. 아이마켓코리아 (종목) (유사도: 0.9133)\n",
      "   6위. iMBC (종목) (유사도: 0.9110)\n",
      "   7위. 지역난방공사 (종목) (유사도: 0.9099)\n",
      "   8위. ISC (종목) (유사도: 0.9075)\n",
      "   9위. 워트 (종목) (유사도: 0.9066)\n",
      "  10위. 오로라 (종목) (유사도: 0.9042)\n",
      "  11위. 한국정보통신 (종목) (유사도: 0.9016)\n",
      "  12위. HD현대에너지솔루션 (종목) (유사도: 0.9016)\n",
      "  13위. HD현대마린엔진 (종목) (유사도: 0.9004)\n",
      "  14위. 대현 (종목) (유사도: 0.8993)\n",
      "  15위. DMS (종목) (유사도: 0.8992)\n",
      "  16위. 동원산업 (종목) (유사도: 0.8978)\n",
      "  17위. 고영 (종목) (유사도: 0.8968)\n",
      "  18위. 수프로 (종목) (유사도: 0.8966)\n",
      "  19위. 인콘 (종목) (유사도: 0.8958)\n",
      "  20위. 셀로맥스사이언스 (종목) (유사도: 0.8954)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-10] 쿼리: '스튜디오드래곤' (종목) ---\n",
      "   1위. BGF리테일 (종목) (유사도: 0.9857)\n",
      "   2위. GS리테일 (종목) (유사도: 0.9849)\n",
      "   3위. 삼성SDI (종목) (유사도: 0.9826)\n",
      "   4위. 뉴로메카 (종목) (유사도: 0.9814)\n",
      "   5위. HD현대중공업 (종목) (유사도: 0.9813)\n",
      "   6위. 이노스페이스 (종목) (유사도: 0.9811)\n",
      "   7위. 현대백화점 (종목) (유사도: 0.9810)\n",
      "   8위. LS (종목) (유사도: 0.9807)\n",
      "   9위. 교촌에프앤비 (종목) (유사도: 0.9806)\n",
      "  10위. 키움증권 (종목) (유사도: 0.9796)\n",
      "  11위. 팬오션 (종목) (유사도: 0.9777)\n",
      "  12위. 아우토크립트 (종목) (유사도: 0.9775)\n",
      "  13위. CJ ENM (종목) (유사도: 0.9774)\n",
      "  14위. 한국항공우주 (종목) (유사도: 0.9767)\n",
      "  15위. 신세계인터내셔날 (종목) (유사도: 0.9750)\n",
      "  16위. DGP (종목) (유사도: 0.9749)\n",
      "  17위. LF (종목) (유사도: 0.9737)\n",
      "  18위. CJ프레시웨이 (종목) (유사도: 0.9735)\n",
      "  19위. DB증권 (종목) (유사도: 0.9731)\n",
      "  20위. 풍산 (종목) (유사도: 0.9717)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "==================================================\n",
      "모든 작업 완료.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- [0. 사전 준비: 전체 탐색 대상(Corpus) 구축] ---\n",
    "# (이전 단계의 final_embeddings_cpu, keyword_map, stock_map, unique_keywords 변수가 \n",
    "#  메모리에 로드되어 있다고 가정합니다.)\n",
    "\n",
    "print(\"--- [0. 전체 탐색 대상 구축 시작] ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "all_nodes_list = []    # (이름, 타입)\n",
    "all_vectors_list = []  # 벡터\n",
    "query_keywords = []    # 1번 작업용 쿼리 리스트\n",
    "query_stocks = []      # 2번 작업용 쿼리 리스트\n",
    "\n",
    "# 1. 모든 '키워드' 노드 추가\n",
    "keyword_matrix = final_embeddings_cpu['keyword']\n",
    "# unique_keywords는 2단계에서 생성된 이름 리스트입니다.\n",
    "for i, name in enumerate(unique_keywords):\n",
    "    if name and name.strip(): # (혹시 모를 빈 키워드 제외)\n",
    "        all_nodes_list.append((name, '키워드'))\n",
    "        all_vectors_list.append(keyword_matrix[i])\n",
    "        query_keywords.append(name) # 쿼리 리스트에도 추가\n",
    "\n",
    "# 2. 모든 '유효한 종목' 노드 추가\n",
    "stock_matrix = final_embeddings_cpu['stock']\n",
    "# stock_map은 2단계에서 생성된 {이름: 인덱스} 딕셔너리입니다.\n",
    "for name, idx in stock_map.items():\n",
    "    if name and name.strip(): # ''(빈 문자열)이 아닌 유효한 종목만\n",
    "        all_nodes_list.append((name, '종목'))\n",
    "        all_vectors_list.append(stock_matrix[idx])\n",
    "        query_stocks.append(name) # 쿼리 리스트에도 추가\n",
    "\n",
    "# 3. Numpy 행렬로 최종 변환\n",
    "all_vectors_matrix = np.vstack(all_vectors_list)\n",
    "total_nodes = len(all_nodes_list)\n",
    "\n",
    "print(f\"총 {total_nodes}개 노드 (키워드 {len(query_keywords)} + 유효 종목 {len(query_stocks)})의 임베딩 행렬 구축 완료.\")\n",
    "print(f\"소요 시간: {time.time() - start_time:.2f}초\")\n",
    "\n",
    "\n",
    "# --- [헬퍼 함수: Top-K 찾기] ---\n",
    "def find_top_k_similar(query_name, query_type, k=20):\n",
    "    \"\"\"\n",
    "    하나의 쿼리(이름, 타입)를 받아,\n",
    "    미리 구축된 'all_vectors_matrix'와 비교하여 \n",
    "    가장 유사한 K개를 반환합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 쿼리 벡터 찾기\n",
    "    query_vector = None\n",
    "    if query_type == '키워드':\n",
    "        if query_name in keyword_map:\n",
    "            query_vector = final_embeddings_cpu['keyword'][keyword_map[query_name]]\n",
    "    elif query_type == '종목':\n",
    "        if query_name in stock_map:\n",
    "            query_vector = final_embeddings_cpu['stock'][stock_map[query_name]]\n",
    "    \n",
    "    if query_vector is None:\n",
    "        print(f\"  오류: '{query_name}'의 벡터를 찾을 수 없습니다.\")\n",
    "        return []\n",
    "\n",
    "    # 2. 코사인 유사도 계산\n",
    "    # (1, N) @ (N, M) -> (1, M)\n",
    "    # N = embedding_dim, M = total_nodes\n",
    "    sim_scores = cosine_similarity(query_vector.reshape(1, -1), all_vectors_matrix)[0]\n",
    "    \n",
    "    # 3. 상위 K개 인덱스 추출 (내림차순)\n",
    "    top_indices = np.argsort(sim_scores)[::-1]\n",
    "    \n",
    "    # 4. 결과 리스트 생성 (자기 자신 제외)\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        if len(results) >= k:\n",
    "            break\n",
    "            \n",
    "        # all_nodes_list에서 정보 가져오기\n",
    "        item_name, item_type = all_nodes_list[idx]\n",
    "        \n",
    "        # 자기 자신은 건너뛰기\n",
    "        if item_name == query_name:\n",
    "            continue\n",
    "            \n",
    "        score = sim_scores[idx]\n",
    "        results.append((item_name, item_type, score))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# --- [1번 작업: 키워드 10개 -> Top 20] ---\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🔍 [작업 1] 랜덤 키워드 10개에 대한 TOP 20 유사 노드\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "N_QUERIES = 10\n",
    "\n",
    "# 1. 쿼리할 키워드 10개 샘플링\n",
    "if len(query_keywords) < N_QUERIES:\n",
    "    print(f\"경고: 키워드 수가 {N_QUERIES}개 미만이라 전체 키워드를 사용합니다.\")\n",
    "    sampled_keywords = query_keywords\n",
    "else:\n",
    "    sampled_keywords = np.random.choice(query_keywords, N_QUERIES, replace=False)\n",
    "\n",
    "# 2. 10개 쿼리 실행\n",
    "for i, query_name in enumerate(sampled_keywords):\n",
    "    print(f\"\\n--- [1-{i+1:2d}] 쿼리: '{query_name}' (키워드) ---\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    top_k_results = find_top_k_similar(query_name, '키워드', k=20)\n",
    "    \n",
    "    if not top_k_results:\n",
    "        print(\"  유사한 노드를 찾지 못했습니다.\")\n",
    "        continue\n",
    "        \n",
    "    for rank, (name, n_type, score) in enumerate(top_k_results):\n",
    "        print(f\"  {rank+1:2d}위. {name} ({n_type}) (유사도: {score:.4f})\")\n",
    "    print(f\"  (소요 시간: {time.time() - start_time:.2f}초)\")\n",
    "\n",
    "\n",
    "# --- [2번 작업: 종목 10개 -> Top 20] ---\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📈 [작업 2] 랜덤 종목 10개에 대한 TOP 20 유사 노드\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. 쿼리할 종목 10개 샘플링\n",
    "if len(query_stocks) < N_QUERIES:\n",
    "    print(f\"경고: 종목 수가 {N_QUERIES}개 미만이라 전체 유효 종목을 사용합니다.\")\n",
    "    sampled_stocks = query_stocks\n",
    "else:\n",
    "    sampled_stocks = np.random.choice(query_stocks, N_QUERIES, replace=False)\n",
    "\n",
    "# 2. 10개 쿼리 실행\n",
    "for i, query_name in enumerate(sampled_stocks):\n",
    "    print(f\"\\n--- [2-{i+1:2d}] 쿼리: '{query_name}' (종목) ---\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    top_k_results = find_top_k_similar(query_name, '종목', k=20)\n",
    "    \n",
    "    if not top_k_results:\n",
    "        print(\"  유사한 노드를 찾지 못했습니다.\")\n",
    "        continue\n",
    "        \n",
    "    for rank, (name, n_type, score) in enumerate(top_k_results):\n",
    "        print(f\"  {rank+1:2d}위. {name} ({n_type}) (유사도: {score:.4f})\")\n",
    "    print(f\"  (소요 시간: {time.time() - start_time:.2f}초)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"모든 작업 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74c9b6161f698eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T05:20:43.992551Z",
     "start_time": "2025-11-13T05:20:43.939026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔍 [작업 1] 랜덤 키워드 10개에 대한 TOP 20 '종목' (Keyword-to-Stock)\n",
      "==================================================\n",
      "\n",
      "--- [1- 1] 쿼리: '권위' (키워드) ---\n",
      "   1위. 현대건설 (종목) (유사도: 0.1273)\n",
      "   2위. 드래곤플라이 (종목) (유사도: 0.1181)\n",
      "   3위. 율촌 (종목) (유사도: 0.1119)\n",
      "   4위. 뉴트리 (종목) (유사도: 0.1109)\n",
      "   5위. 원익 (종목) (유사도: 0.1082)\n",
      "   6위. 오공 (종목) (유사도: 0.0999)\n",
      "   7위. 웹젠 (종목) (유사도: 0.0978)\n",
      "   8위. 신풍 (종목) (유사도: 0.0937)\n",
      "   9위. 선진 (종목) (유사도: 0.0897)\n",
      "  10위. 웅진 (종목) (유사도: 0.0885)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 2] 쿼리: '비율' (키워드) ---\n",
      "   1위. 쌍방울 (종목) (유사도: 0.2362)\n",
      "   2위. 도부 (종목) (유사도: 0.2168)\n",
      "   3위. KB금융 (종목) (유사도: 0.1989)\n",
      "   4위. 사람인 (종목) (유사도: 0.1928)\n",
      "   5위. 혜인 (종목) (유사도: 0.1923)\n",
      "   6위. 디오 (종목) (유사도: 0.1905)\n",
      "   7위. YTN (종목) (유사도: 0.1869)\n",
      "   8위. 신원 (종목) (유사도: 0.1807)\n",
      "   9위. SBS (종목) (유사도: 0.1789)\n",
      "  10위. 엠브레인 (종목) (유사도: 0.1720)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 3] 쿼리: '타입' (키워드) ---\n",
      "   1위. 엠브레인 (종목) (유사도: 0.2078)\n",
      "   2위. 도부 (종목) (유사도: 0.1735)\n",
      "   3위. 신원 (종목) (유사도: 0.1709)\n",
      "   4위. 삼기 (종목) (유사도: 0.1641)\n",
      "   5위. 씨앗 (종목) (유사도: 0.1487)\n",
      "   6위. 진영 (종목) (유사도: 0.1476)\n",
      "   7위. 대원 (종목) (유사도: 0.1328)\n",
      "   8위. 쌍방울 (종목) (유사도: 0.1320)\n",
      "   9위. 대상 (종목) (유사도: 0.1305)\n",
      "  10위. 태양 (종목) (유사도: 0.1301)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 4] 쿼리: '종식' (키워드) ---\n",
      "   1위. 레몬 (종목) (유사도: 0.1289)\n",
      "   2위. 캐리 (종목) (유사도: 0.1225)\n",
      "   3위. 상보 (종목) (유사도: 0.1071)\n",
      "   4위. 이마트 (종목) (유사도: 0.0989)\n",
      "   5위. 신세계 (종목) (유사도: 0.0948)\n",
      "   6위. 키움증권 (종목) (유사도: 0.0855)\n",
      "   7위. 현대백화점 (종목) (유사도: 0.0820)\n",
      "   8위. 캐프 (종목) (유사도: 0.0789)\n",
      "   9위. DB증권 (종목) (유사도: 0.0784)\n",
      "  10위. 신풍 (종목) (유사도: 0.0783)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 5] 쿼리: '허가' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.2982)\n",
      "   2위. 나무가 (종목) (유사도: 0.2373)\n",
      "   3위. 하이브 (종목) (유사도: 0.2091)\n",
      "   4위. SBS (종목) (유사도: 0.2049)\n",
      "   5위. YTN (종목) (유사도: 0.2011)\n",
      "   6위. 신원 (종목) (유사도: 0.1961)\n",
      "   7위. 쌍방울 (종목) (유사도: 0.1948)\n",
      "   8위. KB금융 (종목) (유사도: 0.1944)\n",
      "   9위. 삼기 (종목) (유사도: 0.1910)\n",
      "  10위. 대원 (종목) (유사도: 0.1749)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 6] 쿼리: '사격' (키워드) ---\n",
      "   1위. KG모빌리티 (종목) (유사도: 0.3482)\n",
      "   2위. 나무가 (종목) (유사도: 0.2235)\n",
      "   3위. 하이브 (종목) (유사도: 0.2200)\n",
      "   4위. 서남 (종목) (유사도: 0.1994)\n",
      "   5위. 정다운 (종목) (유사도: 0.1963)\n",
      "   6위. 국보 (종목) (유사도: 0.1872)\n",
      "   7위. 셀트리온 (종목) (유사도: 0.1550)\n",
      "   8위. 골프존 (종목) (유사도: 0.1440)\n",
      "   9위. 진도 (종목) (유사도: 0.1351)\n",
      "  10위. 삼기 (종목) (유사도: 0.1343)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 7] 쿼리: '감사' (키워드) ---\n",
      "   1위. 도부 (종목) (유사도: 0.2667)\n",
      "   2위. 대원 (종목) (유사도: 0.2519)\n",
      "   3위. 신원 (종목) (유사도: 0.2478)\n",
      "   4위. 혜인 (종목) (유사도: 0.2471)\n",
      "   5위. 효성 (종목) (유사도: 0.2446)\n",
      "   6위. 사람인 (종목) (유사도: 0.2424)\n",
      "   7위. YTN (종목) (유사도: 0.2420)\n",
      "   8위. 코리아나 (종목) (유사도: 0.2407)\n",
      "   9위. 파수 (종목) (유사도: 0.2377)\n",
      "  10위. 쌍방울 (종목) (유사도: 0.2372)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 8] 쿼리: '그래픽' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.0768)\n",
      "   2위. 나무가 (종목) (유사도: 0.0487)\n",
      "   3위. 하이브 (종목) (유사도: 0.0359)\n",
      "   4위. SBS (종목) (유사도: 0.0237)\n",
      "   5위. 삼기 (종목) (유사도: 0.0056)\n",
      "   6위. YTN (종목) (유사도: 0.0022)\n",
      "   7위. KB금융 (종목) (유사도: -0.0063)\n",
      "   8위. 카카오 (종목) (유사도: -0.0133)\n",
      "   9위. 쌍방울 (종목) (유사도: -0.0178)\n",
      "  10위. 진도 (종목) (유사도: -0.0221)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1- 9] 쿼리: '즐거움' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.2712)\n",
      "   2위. 나무가 (종목) (유사도: 0.2590)\n",
      "   3위. 하이브 (종목) (유사도: 0.2391)\n",
      "   4위. 삼기 (종목) (유사도: 0.2133)\n",
      "   5위. 정다운 (종목) (유사도: 0.1991)\n",
      "   6위. 쌍방울 (종목) (유사도: 0.1802)\n",
      "   7위. SBS (종목) (유사도: 0.1707)\n",
      "   8위. 국보 (종목) (유사도: 0.1510)\n",
      "   9위. 미래산업 (종목) (유사도: 0.1502)\n",
      "  10위. 상보 (종목) (유사도: 0.1472)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-10] 쿼리: '순차' (키워드) ---\n",
      "   1위. 삼성전자 (종목) (유사도: 0.1747)\n",
      "   2위. 디바이스 (종목) (유사도: 0.1555)\n",
      "   3위. 레이 (종목) (유사도: 0.1487)\n",
      "   4위. 이마트 (종목) (유사도: 0.1472)\n",
      "   5위. 태양 (종목) (유사도: 0.1452)\n",
      "   6위. 코리아나 (종목) (유사도: 0.1392)\n",
      "   7위. 삼일 (종목) (유사도: 0.1310)\n",
      "   8위. 대상 (종목) (유사도: 0.1296)\n",
      "   9위. 현대건설 (종목) (유사도: 0.1255)\n",
      "  10위. 나노 (종목) (유사도: 0.1233)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-11] 쿼리: '방안' (키워드) ---\n",
      "   1위. 도부 (종목) (유사도: 0.3205)\n",
      "   2위. 대상 (종목) (유사도: 0.3076)\n",
      "   3위. 한창 (종목) (유사도: 0.2962)\n",
      "   4위. 전방 (종목) (유사도: 0.2890)\n",
      "   5위. YTN (종목) (유사도: 0.2803)\n",
      "   6위. 효성 (종목) (유사도: 0.2792)\n",
      "   7위. 레이 (종목) (유사도: 0.2769)\n",
      "   8위. 디오 (종목) (유사도: 0.2756)\n",
      "   9위. 사람인 (종목) (유사도: 0.2730)\n",
      "  10위. KB금융 (종목) (유사도: 0.2694)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-12] 쿼리: '급등' (키워드) ---\n",
      "   1위. 엠브레인 (종목) (유사도: 0.2489)\n",
      "   2위. 도부 (종목) (유사도: 0.2093)\n",
      "   3위. 신원 (종목) (유사도: 0.2033)\n",
      "   4위. 진영 (종목) (유사도: 0.1971)\n",
      "   5위. 전방 (종목) (유사도: 0.1760)\n",
      "   6위. 무학 (종목) (유사도: 0.1715)\n",
      "   7위. 씨앗 (종목) (유사도: 0.1683)\n",
      "   8위. 쌍방울 (종목) (유사도: 0.1648)\n",
      "   9위. 대상 (종목) (유사도: 0.1636)\n",
      "  10위. DB (종목) (유사도: 0.1624)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-13] 쿼리: '매우' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.2679)\n",
      "   2위. 나무가 (종목) (유사도: 0.2623)\n",
      "   3위. 하이브 (종목) (유사도: 0.2591)\n",
      "   4위. 신원 (종목) (유사도: 0.2338)\n",
      "   5위. 진도 (종목) (유사도: 0.2214)\n",
      "   6위. 정다운 (종목) (유사도: 0.2212)\n",
      "   7위. 삼기 (종목) (유사도: 0.2192)\n",
      "   8위. 국보 (종목) (유사도: 0.2177)\n",
      "   9위. 대원 (종목) (유사도: 0.2172)\n",
      "  10위. YTN (종목) (유사도: 0.2133)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-14] 쿼리: '제자' (키워드) ---\n",
      "   1위. KG모빌리티 (종목) (유사도: 0.1928)\n",
      "   2위. 선진 (종목) (유사도: 0.1486)\n",
      "   3위. 삼기 (종목) (유사도: 0.1454)\n",
      "   4위. 율촌 (종목) (유사도: 0.1399)\n",
      "   5위. 나무가 (종목) (유사도: 0.1360)\n",
      "   6위. 하이브 (종목) (유사도: 0.1333)\n",
      "   7위. 골프존 (종목) (유사도: 0.1299)\n",
      "   8위. 현대건설 (종목) (유사도: 0.1185)\n",
      "   9위. 호텔신라 (종목) (유사도: 0.1138)\n",
      "  10위. 대원 (종목) (유사도: 0.1122)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-15] 쿼리: '기소' (키워드) ---\n",
      "   1위. 나무가 (종목) (유사도: 0.2403)\n",
      "   2위. 정다운 (종목) (유사도: 0.2231)\n",
      "   3위. 하이브 (종목) (유사도: 0.2230)\n",
      "   4위. 국보 (종목) (유사도: 0.2054)\n",
      "   5위. 파수 (종목) (유사도: 0.1977)\n",
      "   6위. KG모빌리티 (종목) (유사도: 0.1646)\n",
      "   7위. 혜인 (종목) (유사도: 0.1625)\n",
      "   8위. 캐리 (종목) (유사도: 0.1499)\n",
      "   9위. 진도 (종목) (유사도: 0.1441)\n",
      "  10위. 성우 (종목) (유사도: 0.1397)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-16] 쿼리: '이용자' (키워드) ---\n",
      "   1위. 삼성전자 (종목) (유사도: 0.2993)\n",
      "   2위. 코리아나 (종목) (유사도: 0.2843)\n",
      "   3위. 레이 (종목) (유사도: 0.2804)\n",
      "   4위. 디바이스 (종목) (유사도: 0.2762)\n",
      "   5위. 씨앗 (종목) (유사도: 0.2708)\n",
      "   6위. DB (종목) (유사도: 0.2653)\n",
      "   7위. 태양 (종목) (유사도: 0.2627)\n",
      "   8위. 서원 (종목) (유사도: 0.2520)\n",
      "   9위. NEW (종목) (유사도: 0.2513)\n",
      "  10위. 대상 (종목) (유사도: 0.2501)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-17] 쿼리: '시민' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.1499)\n",
      "   2위. 도부 (종목) (유사도: 0.1490)\n",
      "   3위. 효성 (종목) (유사도: 0.1457)\n",
      "   4위. YTN (종목) (유사도: 0.1454)\n",
      "   5위. 쌍방울 (종목) (유사도: 0.1381)\n",
      "   6위. 코리아나 (종목) (유사도: 0.1366)\n",
      "   7위. 사람인 (종목) (유사도: 0.1352)\n",
      "   8위. 전방 (종목) (유사도: 0.1300)\n",
      "   9위. KB금융 (종목) (유사도: 0.1299)\n",
      "  10위. SBS (종목) (유사도: 0.1293)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-18] 쿼리: '청장' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.2630)\n",
      "   2위. SBS (종목) (유사도: 0.2230)\n",
      "   3위. YTN (종목) (유사도: 0.2227)\n",
      "   4위. 나무가 (종목) (유사도: 0.2226)\n",
      "   5위. KB금융 (종목) (유사도: 0.2119)\n",
      "   6위. 쌍방울 (종목) (유사도: 0.2073)\n",
      "   7위. 하이브 (종목) (유사도: 0.2065)\n",
      "   8위. 카카오 (종목) (유사도: 0.2057)\n",
      "   9위. 효성 (종목) (유사도: 0.1924)\n",
      "  10위. 성우 (종목) (유사도: 0.1844)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-19] 쿼리: '가라' (키워드) ---\n",
      "   1위. KG모빌리티 (종목) (유사도: 0.3102)\n",
      "   2위. 국보 (종목) (유사도: 0.2041)\n",
      "   3위. 골프존 (종목) (유사도: 0.1922)\n",
      "   4위. 서남 (종목) (유사도: 0.1880)\n",
      "   5위. 셀트리온 (종목) (유사도: 0.1871)\n",
      "   6위. 나무가 (종목) (유사도: 0.1787)\n",
      "   7위. 율촌 (종목) (유사도: 0.1728)\n",
      "   8위. 하이브 (종목) (유사도: 0.1676)\n",
      "   9위. 정다운 (종목) (유사도: 0.1635)\n",
      "  10위. 기아 (종목) (유사도: 0.1611)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-20] 쿼리: '상대' (키워드) ---\n",
      "   1위. 삼기 (종목) (유사도: 0.2559)\n",
      "   2위. 나무가 (종목) (유사도: 0.2303)\n",
      "   3위. 혜인 (종목) (유사도: 0.2217)\n",
      "   4위. 하이브 (종목) (유사도: 0.1942)\n",
      "   5위. 대원 (종목) (유사도: 0.1840)\n",
      "   6위. 선진 (종목) (유사도: 0.1814)\n",
      "   7위. 신원 (종목) (유사도: 0.1765)\n",
      "   8위. SBS (종목) (유사도: 0.1729)\n",
      "   9위. 진도 (종목) (유사도: 0.1706)\n",
      "  10위. YTN (종목) (유사도: 0.1687)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-21] 쿼리: '이어진' (키워드) ---\n",
      "   1위. 한화 (종목) (유사도: 0.1562)\n",
      "   2위. 현대건설 (종목) (유사도: 0.1517)\n",
      "   3위. 레이 (종목) (유사도: 0.1428)\n",
      "   4위. 삼성전자 (종목) (유사도: 0.1402)\n",
      "   5위. 디바이스 (종목) (유사도: 0.1332)\n",
      "   6위. 이마트 (종목) (유사도: 0.1314)\n",
      "   7위. 태양 (종목) (유사도: 0.1259)\n",
      "   8위. GS (종목) (유사도: 0.1239)\n",
      "   9위. 골프존 (종목) (유사도: 0.1186)\n",
      "  10위. 링크드 (종목) (유사도: 0.1162)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-22] 쿼리: '반환' (키워드) ---\n",
      "   1위. 쌍방울 (종목) (유사도: 0.1910)\n",
      "   2위. 엠브레인 (종목) (유사도: 0.1641)\n",
      "   3위. 도부 (종목) (유사도: 0.1465)\n",
      "   4위. KB금융 (종목) (유사도: 0.1370)\n",
      "   5위. 혜인 (종목) (유사도: 0.1329)\n",
      "   6위. 사람인 (종목) (유사도: 0.1314)\n",
      "   7위. 대교 (종목) (유사도: 0.1224)\n",
      "   8위. 디오 (종목) (유사도: 0.1199)\n",
      "   9위. YTN (종목) (유사도: 0.1166)\n",
      "  10위. 조비 (종목) (유사도: 0.1136)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-23] 쿼리: '언론' (키워드) ---\n",
      "   1위. 나무가 (종목) (유사도: 0.2064)\n",
      "   2위. 하이브 (종목) (유사도: 0.1674)\n",
      "   3위. 혜인 (종목) (유사도: 0.1558)\n",
      "   4위. 정다운 (종목) (유사도: 0.1552)\n",
      "   5위. 국보 (종목) (유사도: 0.1512)\n",
      "   6위. 캐리 (종목) (유사도: 0.1416)\n",
      "   7위. 파수 (종목) (유사도: 0.1312)\n",
      "   8위. 상보 (종목) (유사도: 0.1094)\n",
      "   9위. 성우 (종목) (유사도: 0.1084)\n",
      "  10위. YTN (종목) (유사도: 0.1066)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-24] 쿼리: '돼지' (키워드) ---\n",
      "   1위. 삼기 (종목) (유사도: 0.2311)\n",
      "   2위. KG모빌리티 (종목) (유사도: 0.2272)\n",
      "   3위. 혜인 (종목) (유사도: 0.2191)\n",
      "   4위. 하이브 (종목) (유사도: 0.1770)\n",
      "   5위. 나무가 (종목) (유사도: 0.1683)\n",
      "   6위. 신원 (종목) (유사도: 0.1588)\n",
      "   7위. 미래산업 (종목) (유사도: 0.1416)\n",
      "   8위. 쌍방울 (종목) (유사도: 0.1389)\n",
      "   9위. 에스코넥 (종목) (유사도: 0.1368)\n",
      "  10위. 정다운 (종목) (유사도: 0.1307)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-25] 쿼리: '장외' (키워드) ---\n",
      "   1위. KG모빌리티 (종목) (유사도: 0.2520)\n",
      "   2위. 나무가 (종목) (유사도: 0.2414)\n",
      "   3위. 정다운 (종목) (유사도: 0.2378)\n",
      "   4위. 국보 (종목) (유사도: 0.2304)\n",
      "   5위. 하이브 (종목) (유사도: 0.2263)\n",
      "   6위. 파수 (종목) (유사도: 0.2174)\n",
      "   7위. 코리아나 (종목) (유사도: 0.1950)\n",
      "   8위. 서남 (종목) (유사도: 0.1860)\n",
      "   9위. 캐리 (종목) (유사도: 0.1837)\n",
      "  10위. NEW (종목) (유사도: 0.1680)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-26] 쿼리: '자재' (키워드) ---\n",
      "   1위. 혜인 (종목) (유사도: 0.1785)\n",
      "   2위. 나무가 (종목) (유사도: 0.1745)\n",
      "   3위. 하이브 (종목) (유사도: 0.1605)\n",
      "   4위. 삼기 (종목) (유사도: 0.1228)\n",
      "   5위. 정다운 (종목) (유사도: 0.1136)\n",
      "   6위. 상보 (종목) (유사도: 0.1121)\n",
      "   7위. 국보 (종목) (유사도: 0.1001)\n",
      "   8위. KG모빌리티 (종목) (유사도: 0.0922)\n",
      "   9위. 쌍방울 (종목) (유사도: 0.0916)\n",
      "  10위. 캐리 (종목) (유사도: 0.0915)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-27] 쿼리: '항소심' (키워드) ---\n",
      "   1위. 나무가 (종목) (유사도: 0.2008)\n",
      "   2위. 정다운 (종목) (유사도: 0.1957)\n",
      "   3위. 국보 (종목) (유사도: 0.1895)\n",
      "   4위. KG모빌리티 (종목) (유사도: 0.1827)\n",
      "   5위. 하이브 (종목) (유사도: 0.1809)\n",
      "   6위. 파수 (종목) (유사도: 0.1535)\n",
      "   7위. 혜인 (종목) (유사도: 0.1302)\n",
      "   8위. 셀트리온 (종목) (유사도: 0.1135)\n",
      "   9위. 미래산업 (종목) (유사도: 0.1063)\n",
      "  10위. 캐리 (종목) (유사도: 0.0950)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-28] 쿼리: '서울중앙지법' (키워드) ---\n",
      "   1위. 나무가 (종목) (유사도: 0.2168)\n",
      "   2위. 국보 (종목) (유사도: 0.2068)\n",
      "   3위. 정다운 (종목) (유사도: 0.2048)\n",
      "   4위. KG모빌리티 (종목) (유사도: 0.2028)\n",
      "   5위. 하이브 (종목) (유사도: 0.1890)\n",
      "   6위. 파수 (종목) (유사도: 0.1773)\n",
      "   7위. 혜인 (종목) (유사도: 0.1557)\n",
      "   8위. 셀트리온 (종목) (유사도: 0.1334)\n",
      "   9위. 미래산업 (종목) (유사도: 0.1312)\n",
      "  10위. 상보 (종목) (유사도: 0.1272)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-29] 쿼리: '상의' (키워드) ---\n",
      "   1위. 나무가 (종목) (유사도: 0.2054)\n",
      "   2위. 혜인 (종목) (유사도: 0.1820)\n",
      "   3위. KG모빌리티 (종목) (유사도: 0.1783)\n",
      "   4위. 하이브 (종목) (유사도: 0.1730)\n",
      "   5위. 삼기 (종목) (유사도: 0.1702)\n",
      "   6위. 신원 (종목) (유사도: 0.1437)\n",
      "   7위. 진도 (종목) (유사도: 0.1273)\n",
      "   8위. 대원 (종목) (유사도: 0.1263)\n",
      "   9위. 국보 (종목) (유사도: 0.1090)\n",
      "  10위. SBS (종목) (유사도: 0.1045)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [1-30] 쿼리: '하림' (키워드) ---\n",
      "   1위. 엠브레인 (종목) (유사도: 0.2260)\n",
      "   2위. 도부 (종목) (유사도: 0.1858)\n",
      "   3위. 태양 (종목) (유사도: 0.1858)\n",
      "   4위. 진영 (종목) (유사도: 0.1834)\n",
      "   5위. 서원 (종목) (유사도: 0.1829)\n",
      "   6위. DB (종목) (유사도: 0.1806)\n",
      "   7위. 씨앗 (종목) (유사도: 0.1795)\n",
      "   8위. 우성 (종목) (유사도: 0.1786)\n",
      "   9위. 우리로 (종목) (유사도: 0.1770)\n",
      "  10위. 대상 (종목) (유사도: 0.1689)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "==================================================\n",
      "📈 [작업 2] 랜덤 종목 10개에 대한 TOP 20 '키워드' (Stock-to-Keyword)\n",
      "==================================================\n",
      "\n",
      "--- [2- 1] 쿼리: '동일스틸럭스' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2677)\n",
      "   2위. 남녀 (키워드) (유사도: 0.2235)\n",
      "   3위. 계세 (키워드) (유사도: 0.2194)\n",
      "   4위. 가기 (키워드) (유사도: 0.1701)\n",
      "   5위. 시야 (키워드) (유사도: 0.1657)\n",
      "   6위. 일시 (키워드) (유사도: 0.1611)\n",
      "   7위. 나선 (키워드) (유사도: 0.1595)\n",
      "   8위. 분수령 (키워드) (유사도: 0.1573)\n",
      "   9위. 서명 (키워드) (유사도: 0.1561)\n",
      "  10위. 익명 (키워드) (유사도: 0.1561)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 2] 쿼리: '쏘카' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.2338)\n",
      "   2위. 상대로 (키워드) (유사도: 0.2335)\n",
      "   3위. 계세 (키워드) (유사도: 0.1895)\n",
      "   4위. 남녀 (키워드) (유사도: 0.1867)\n",
      "   5위. 산업부 (키워드) (유사도: 0.1673)\n",
      "   6위. 영감 (키워드) (유사도: 0.1661)\n",
      "   7위. 뱅킹 (키워드) (유사도: 0.1659)\n",
      "   8위. 시야 (키워드) (유사도: 0.1581)\n",
      "   9위. 양질 (키워드) (유사도: 0.1512)\n",
      "  10위. 가기 (키워드) (유사도: 0.1479)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 3] 쿼리: '컴투스홀딩스' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.3134)\n",
      "   2위. 영감 (키워드) (유사도: 0.2697)\n",
      "   3위. 뱅킹 (키워드) (유사도: 0.2686)\n",
      "   4위. 캐피탈 (키워드) (유사도: 0.2393)\n",
      "   5위. 계세 (키워드) (유사도: 0.2349)\n",
      "   6위. 점점 (키워드) (유사도: 0.2323)\n",
      "   7위. 안정화 (키워드) (유사도: 0.2279)\n",
      "   8위. 토레스 (키워드) (유사도: 0.2254)\n",
      "   9위. 양질 (키워드) (유사도: 0.2249)\n",
      "  10위. 표본 (키워드) (유사도: 0.2243)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 4] 쿼리: '에이치엔에스하이텍' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2593)\n",
      "   2위. 계세 (키워드) (유사도: 0.2294)\n",
      "   3위. 일시 (키워드) (유사도: 0.2228)\n",
      "   4위. 남녀 (키워드) (유사도: 0.2066)\n",
      "   5위. 영감 (키워드) (유사도: 0.2038)\n",
      "   6위. 서명 (키워드) (유사도: 0.1858)\n",
      "   7위. 시야 (키워드) (유사도: 0.1800)\n",
      "   8위. 안정화 (키워드) (유사도: 0.1638)\n",
      "   9위. 가기 (키워드) (유사도: 0.1623)\n",
      "  10위. 익명 (키워드) (유사도: 0.1591)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 5] 쿼리: '우성' (종목) ---\n",
      "   1위. 캐피탈 (키워드) (유사도: 0.3590)\n",
      "   2위. 구현 (키워드) (유사도: 0.3407)\n",
      "   3위. 뱅킹 (키워드) (유사도: 0.3201)\n",
      "   4위. 선진국 (키워드) (유사도: 0.3174)\n",
      "   5위. 공작 (키워드) (유사도: 0.3093)\n",
      "   6위. 동남아 (키워드) (유사도: 0.3013)\n",
      "   7위. 대담 (키워드) (유사도: 0.2989)\n",
      "   8위. 억제 (키워드) (유사도: 0.2978)\n",
      "   9위. 메인 (키워드) (유사도: 0.2977)\n",
      "  10위. 단일 (키워드) (유사도: 0.2916)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 6] 쿼리: '컴투스' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2457)\n",
      "   2위. 계세 (키워드) (유사도: 0.2090)\n",
      "   3위. 익명 (키워드) (유사도: 0.1903)\n",
      "   4위. 가기 (키워드) (유사도: 0.1894)\n",
      "   5위. 영감 (키워드) (유사도: 0.1824)\n",
      "   6위. 서명 (키워드) (유사도: 0.1745)\n",
      "   7위. 환상 (키워드) (유사도: 0.1588)\n",
      "   8위. 법치 (키워드) (유사도: 0.1561)\n",
      "   9위. 관례 (키워드) (유사도: 0.1539)\n",
      "  10위. 그대로 (키워드) (유사도: 0.1519)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 7] 쿼리: '에이비온' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.2894)\n",
      "   2위. 영감 (키워드) (유사도: 0.2509)\n",
      "   3위. 계세 (키워드) (유사도: 0.2443)\n",
      "   4위. 안정화 (키워드) (유사도: 0.2283)\n",
      "   5위. 상대로 (키워드) (유사도: 0.2273)\n",
      "   6위. 뱅킹 (키워드) (유사도: 0.2190)\n",
      "   7위. 시야 (키워드) (유사도: 0.2114)\n",
      "   8위. 캐피탈 (키워드) (유사도: 0.2060)\n",
      "   9위. 익명 (키워드) (유사도: 0.1997)\n",
      "  10위. 남녀 (키워드) (유사도: 0.1979)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 8] 쿼리: '코웨이' (종목) ---\n",
      "   1위. 계세 (키워드) (유사도: 0.1992)\n",
      "   2위. 익명 (키워드) (유사도: 0.1977)\n",
      "   3위. 선진국 (키워드) (유사도: 0.1839)\n",
      "   4위. 캐피탈 (키워드) (유사도: 0.1738)\n",
      "   5위. 텍스트 (키워드) (유사도: 0.1700)\n",
      "   6위. 주연 (키워드) (유사도: 0.1683)\n",
      "   7위. 오스 (키워드) (유사도: 0.1644)\n",
      "   8위. 인도네시아 (키워드) (유사도: 0.1625)\n",
      "   9위. 대리인 (키워드) (유사도: 0.1612)\n",
      "  10위. 창조 (키워드) (유사도: 0.1603)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2- 9] 쿼리: '노루페인트' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2172)\n",
      "   2위. 계세 (키워드) (유사도: 0.2087)\n",
      "   3위. 영감 (키워드) (유사도: 0.1587)\n",
      "   4위. 남녀 (키워드) (유사도: 0.1563)\n",
      "   5위. 익명 (키워드) (유사도: 0.1527)\n",
      "   6위. 서명 (키워드) (유사도: 0.1519)\n",
      "   7위. 캐피탈 (키워드) (유사도: 0.1487)\n",
      "   8위. 일시 (키워드) (유사도: 0.1479)\n",
      "   9위. 양종 (키워드) (유사도: 0.1442)\n",
      "  10위. 시야 (키워드) (유사도: 0.1429)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-10] 쿼리: '엔젠바이오' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2277)\n",
      "   2위. 계세 (키워드) (유사도: 0.1948)\n",
      "   3위. 영감 (키워드) (유사도: 0.1525)\n",
      "   4위. 가기 (키워드) (유사도: 0.1480)\n",
      "   5위. 남녀 (키워드) (유사도: 0.1431)\n",
      "   6위. 익명 (키워드) (유사도: 0.1414)\n",
      "   7위. 점점 (키워드) (유사도: 0.1342)\n",
      "   8위. 시야 (키워드) (유사도: 0.1333)\n",
      "   9위. 서명 (키워드) (유사도: 0.1329)\n",
      "  10위. 양종 (키워드) (유사도: 0.1260)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-11] 쿼리: '모비스' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2479)\n",
      "   2위. 계세 (키워드) (유사도: 0.1630)\n",
      "   3위. 남녀 (키워드) (유사도: 0.1482)\n",
      "   4위. 익명 (키워드) (유사도: 0.1469)\n",
      "   5위. 일시 (키워드) (유사도: 0.1469)\n",
      "   6위. 거짓 (키워드) (유사도: 0.1344)\n",
      "   7위. 서명 (키워드) (유사도: 0.1301)\n",
      "   8위. 영감 (키워드) (유사도: 0.1187)\n",
      "   9위. 태평양 (키워드) (유사도: 0.1180)\n",
      "  10위. 가기 (키워드) (유사도: 0.1112)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-12] 쿼리: '효성중공업' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2426)\n",
      "   2위. 일시 (키워드) (유사도: 0.2149)\n",
      "   3위. 계세 (키워드) (유사도: 0.1977)\n",
      "   4위. 남녀 (키워드) (유사도: 0.1713)\n",
      "   5위. 영감 (키워드) (유사도: 0.1674)\n",
      "   6위. 익명 (키워드) (유사도: 0.1601)\n",
      "   7위. 서명 (키워드) (유사도: 0.1553)\n",
      "   8위. 시야 (키워드) (유사도: 0.1519)\n",
      "   9위. 가기 (키워드) (유사도: 0.1493)\n",
      "  10위. 뱅킹 (키워드) (유사도: 0.1413)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-13] 쿼리: '링크드' (종목) ---\n",
      "   1위. 주연 (키워드) (유사도: 0.2925)\n",
      "   2위. 박정훈 (키워드) (유사도: 0.2886)\n",
      "   3위. 형태 (키워드) (유사도: 0.2851)\n",
      "   4위. 대규모 (키워드) (유사도: 0.2748)\n",
      "   5위. 플레이스토어 (키워드) (유사도: 0.2730)\n",
      "   6위. 동선 (키워드) (유사도: 0.2716)\n",
      "   7위. 피드 (키워드) (유사도: 0.2708)\n",
      "   8위. 내비 (키워드) (유사도: 0.2674)\n",
      "   9위. 대외 (키워드) (유사도: 0.2662)\n",
      "  10위. 그대로 (키워드) (유사도: 0.2643)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-14] 쿼리: 'SB성보' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2474)\n",
      "   2위. 영감 (키워드) (유사도: 0.2342)\n",
      "   3위. 일시 (키워드) (유사도: 0.2262)\n",
      "   4위. 계세 (키워드) (유사도: 0.2153)\n",
      "   5위. 캐피탈 (키워드) (유사도: 0.2028)\n",
      "   6위. 서명 (키워드) (유사도: 0.1890)\n",
      "   7위. 기조 (키워드) (유사도: 0.1816)\n",
      "   8위. 시야 (키워드) (유사도: 0.1799)\n",
      "   9위. 점점 (키워드) (유사도: 0.1788)\n",
      "  10위. 가기 (키워드) (유사도: 0.1783)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-15] 쿼리: '원준' (종목) ---\n",
      "   1위. 계세 (키워드) (유사도: 0.1778)\n",
      "   2위. 캐피탈 (키워드) (유사도: 0.1742)\n",
      "   3위. 상대로 (키워드) (유사도: 0.1742)\n",
      "   4위. 선진국 (키워드) (유사도: 0.1563)\n",
      "   5위. 영감 (키워드) (유사도: 0.1525)\n",
      "   6위. 표본 (키워드) (유사도: 0.1485)\n",
      "   7위. 일시 (키워드) (유사도: 0.1479)\n",
      "   8위. 억제 (키워드) (유사도: 0.1447)\n",
      "   9위. 방치 (키워드) (유사도: 0.1387)\n",
      "  10위. 오스 (키워드) (유사도: 0.1377)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-16] 쿼리: '삼성물산' (종목) ---\n",
      "   1위. 계세 (키워드) (유사도: 0.2641)\n",
      "   2위. 선진국 (키워드) (유사도: 0.2087)\n",
      "   3위. 가기 (키워드) (유사도: 0.2062)\n",
      "   4위. 그대로 (키워드) (유사도: 0.2055)\n",
      "   5위. 공작 (키워드) (유사도: 0.2045)\n",
      "   6위. 동선 (키워드) (유사도: 0.2012)\n",
      "   7위. 시야 (키워드) (유사도: 0.1991)\n",
      "   8위. 영감 (키워드) (유사도: 0.1977)\n",
      "   9위. 방치 (키워드) (유사도: 0.1961)\n",
      "  10위. 익명 (키워드) (유사도: 0.1945)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-17] 쿼리: '씨젠' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.2980)\n",
      "   2위. 영감 (키워드) (유사도: 0.2370)\n",
      "   3위. 토레스 (키워드) (유사도: 0.2335)\n",
      "   4위. 뱅킹 (키워드) (유사도: 0.2333)\n",
      "   5위. 양질 (키워드) (유사도: 0.2310)\n",
      "   6위. 캐피탈 (키워드) (유사도: 0.2280)\n",
      "   7위. 산업부 (키워드) (유사도: 0.2235)\n",
      "   8위. 도모 (키워드) (유사도: 0.2072)\n",
      "   9위. 상대로 (키워드) (유사도: 0.2037)\n",
      "  10위. 표본 (키워드) (유사도: 0.2004)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-18] 쿼리: '다올투자증권' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.1874)\n",
      "   2위. 계세 (키워드) (유사도: 0.1849)\n",
      "   3위. 익명 (키워드) (유사도: 0.1722)\n",
      "   4위. 가기 (키워드) (유사도: 0.1636)\n",
      "   5위. 오스 (키워드) (유사도: 0.1409)\n",
      "   6위. 트랙 (키워드) (유사도: 0.1327)\n",
      "   7위. 창조 (키워드) (유사도: 0.1301)\n",
      "   8위. 캐피탈 (키워드) (유사도: 0.1290)\n",
      "   9위. 아마 (키워드) (유사도: 0.1260)\n",
      "  10위. 법치 (키워드) (유사도: 0.1256)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-19] 쿼리: 'SK' (종목) ---\n",
      "   1위. 아시아 (키워드) (유사도: 0.3011)\n",
      "   2위. 월간 (키워드) (유사도: 0.2760)\n",
      "   3위. 토스 (키워드) (유사도: 0.2682)\n",
      "   4위. 형태 (키워드) (유사도: 0.2594)\n",
      "   5위. 팩토리 (키워드) (유사도: 0.2520)\n",
      "   6위. 주연 (키워드) (유사도: 0.2513)\n",
      "   7위. 청산 (키워드) (유사도: 0.2452)\n",
      "   8위. 내비 (키워드) (유사도: 0.2450)\n",
      "   9위. 수수료 (키워드) (유사도: 0.2446)\n",
      "  10위. 공작 (키워드) (유사도: 0.2430)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-20] 쿼리: '조이시티' (종목) ---\n",
      "   1위. 영감 (키워드) (유사도: 0.2649)\n",
      "   2위. 상대로 (키워드) (유사도: 0.2302)\n",
      "   3위. 일시 (키워드) (유사도: 0.2278)\n",
      "   4위. 계세 (키워드) (유사도: 0.2274)\n",
      "   5위. 캐피탈 (키워드) (유사도: 0.2234)\n",
      "   6위. 안정화 (키워드) (유사도: 0.2195)\n",
      "   7위. 익명 (키워드) (유사도: 0.2111)\n",
      "   8위. 기조 (키워드) (유사도: 0.2099)\n",
      "   9위. 점점 (키워드) (유사도: 0.1954)\n",
      "  10위. 가기 (키워드) (유사도: 0.1947)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-21] 쿼리: '메카로' (종목) ---\n",
      "   1위. 뱅킹 (키워드) (유사도: 0.3333)\n",
      "   2위. 공작 (키워드) (유사도: 0.3121)\n",
      "   3위. 선진국 (키워드) (유사도: 0.3083)\n",
      "   4위. 표본 (키워드) (유사도: 0.2995)\n",
      "   5위. 캐피탈 (키워드) (유사도: 0.2902)\n",
      "   6위. 메인 (키워드) (유사도: 0.2852)\n",
      "   7위. 점점 (키워드) (유사도: 0.2816)\n",
      "   8위. 영감 (키워드) (유사도: 0.2748)\n",
      "   9위. 일시 (키워드) (유사도: 0.2723)\n",
      "  10위. 박정훈 (키워드) (유사도: 0.2714)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-22] 쿼리: '덴티움' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.3062)\n",
      "   2위. 영감 (키워드) (유사도: 0.2598)\n",
      "   3위. 상대로 (키워드) (유사도: 0.2474)\n",
      "   4위. 캐피탈 (키워드) (유사도: 0.2314)\n",
      "   5위. 계세 (키워드) (유사도: 0.2265)\n",
      "   6위. 방치 (키워드) (유사도: 0.2254)\n",
      "   7위. 안정화 (키워드) (유사도: 0.2166)\n",
      "   8위. 기조 (키워드) (유사도: 0.2124)\n",
      "   9위. 시야 (키워드) (유사도: 0.2064)\n",
      "  10위. 뱅킹 (키워드) (유사도: 0.2044)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-23] 쿼리: '현대건설' (종목) ---\n",
      "   1위. 내비 (키워드) (유사도: 0.2842)\n",
      "   2위. 형태 (키워드) (유사도: 0.2790)\n",
      "   3위. 아시아 (키워드) (유사도: 0.2754)\n",
      "   4위. 월간 (키워드) (유사도: 0.2752)\n",
      "   5위. 동선 (키워드) (유사도: 0.2706)\n",
      "   6위. 대외 (키워드) (유사도: 0.2695)\n",
      "   7위. 주연 (키워드) (유사도: 0.2694)\n",
      "   8위. 팩토리 (키워드) (유사도: 0.2639)\n",
      "   9위. 뭔가 (키워드) (유사도: 0.2628)\n",
      "  10위. 예배 (키워드) (유사도: 0.2520)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-24] 쿼리: '삼성중공업' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.2406)\n",
      "   2위. 계세 (키워드) (유사도: 0.2369)\n",
      "   3위. 뱅킹 (키워드) (유사도: 0.2217)\n",
      "   4위. 영감 (키워드) (유사도: 0.2086)\n",
      "   5위. 상대로 (키워드) (유사도: 0.2078)\n",
      "   6위. 시야 (키워드) (유사도: 0.1948)\n",
      "   7위. 양질 (키워드) (유사도: 0.1887)\n",
      "   8위. 표본 (키워드) (유사도: 0.1885)\n",
      "   9위. 선진국 (키워드) (유사도: 0.1834)\n",
      "  10위. 점점 (키워드) (유사도: 0.1822)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-25] 쿼리: 'SG' (종목) ---\n",
      "   1위. 아시아 (키워드) (유사도: 0.3546)\n",
      "   2위. 촉진 (키워드) (유사도: 0.3320)\n",
      "   3위. 공작 (키워드) (유사도: 0.3263)\n",
      "   4위. 구현 (키워드) (유사도: 0.3246)\n",
      "   5위. 메인 (키워드) (유사도: 0.3196)\n",
      "   6위. 수수료 (키워드) (유사도: 0.3167)\n",
      "   7위. 토스 (키워드) (유사도: 0.3091)\n",
      "   8위. 뱅킹 (키워드) (유사도: 0.3086)\n",
      "   9위. 보증 (키워드) (유사도: 0.3085)\n",
      "  10위. 지면 (키워드) (유사도: 0.3082)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-26] 쿼리: 'HL D&I' (종목) ---\n",
      "   1위. 일시 (키워드) (유사도: 0.2844)\n",
      "   2위. 상대로 (키워드) (유사도: 0.2508)\n",
      "   3위. 영감 (키워드) (유사도: 0.2444)\n",
      "   4위. 계세 (키워드) (유사도: 0.2424)\n",
      "   5위. 시야 (키워드) (유사도: 0.2107)\n",
      "   6위. 뱅킹 (키워드) (유사도: 0.2089)\n",
      "   7위. 남녀 (키워드) (유사도: 0.2049)\n",
      "   8위. 안정화 (키워드) (유사도: 0.2035)\n",
      "   9위. 캐피탈 (키워드) (유사도: 0.1984)\n",
      "  10위. 서명 (키워드) (유사도: 0.1973)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-27] 쿼리: '더존비즈온' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2448)\n",
      "   2위. 계세 (키워드) (유사도: 0.2101)\n",
      "   3위. 일시 (키워드) (유사도: 0.1973)\n",
      "   4위. 영감 (키워드) (유사도: 0.1883)\n",
      "   5위. 남녀 (키워드) (유사도: 0.1858)\n",
      "   6위. 시야 (키워드) (유사도: 0.1718)\n",
      "   7위. 가기 (키워드) (유사도: 0.1611)\n",
      "   8위. 서명 (키워드) (유사도: 0.1581)\n",
      "   9위. 익명 (키워드) (유사도: 0.1552)\n",
      "  10위. 방치 (키워드) (유사도: 0.1542)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-28] 쿼리: '한화오션' (종목) ---\n",
      "   1위. 캐피탈 (키워드) (유사도: 0.2715)\n",
      "   2위. 계세 (키워드) (유사도: 0.2678)\n",
      "   3위. 영감 (키워드) (유사도: 0.2635)\n",
      "   4위. 선진국 (키워드) (유사도: 0.2600)\n",
      "   5위. 공작 (키워드) (유사도: 0.2562)\n",
      "   6위. 점점 (키워드) (유사도: 0.2529)\n",
      "   7위. 표본 (키워드) (유사도: 0.2474)\n",
      "   8위. 기조 (키워드) (유사도: 0.2426)\n",
      "   9위. 시야 (키워드) (유사도: 0.2338)\n",
      "  10위. 뱅킹 (키워드) (유사도: 0.2331)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-29] 쿼리: '한익스프레스' (종목) ---\n",
      "   1위. 상대로 (키워드) (유사도: 0.2365)\n",
      "   2위. 일시 (키워드) (유사도: 0.2153)\n",
      "   3위. 계세 (키워드) (유사도: 0.1905)\n",
      "   4위. 익명 (키워드) (유사도: 0.1701)\n",
      "   5위. 영감 (키워드) (유사도: 0.1684)\n",
      "   6위. 남녀 (키워드) (유사도: 0.1640)\n",
      "   7위. 서명 (키워드) (유사도: 0.1565)\n",
      "   8위. 안정화 (키워드) (유사도: 0.1534)\n",
      "   9위. 명도 (키워드) (유사도: 0.1493)\n",
      "  10위. 방치 (키워드) (유사도: 0.1481)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "--- [2-30] 쿼리: '디오' (종목) ---\n",
      "   1위. 개막 (키워드) (유사도: 0.3411)\n",
      "   2위. 바닥 (키워드) (유사도: 0.3276)\n",
      "   3위. 배당 (키워드) (유사도: 0.3243)\n",
      "   4위. 아시아 (키워드) (유사도: 0.3216)\n",
      "   5위. 한번 (키워드) (유사도: 0.3209)\n",
      "   6위. 캐나다 (키워드) (유사도: 0.3183)\n",
      "   7위. 경우 (키워드) (유사도: 0.3182)\n",
      "   8위. 가게 (키워드) (유사도: 0.3169)\n",
      "   9위. 무산 (키워드) (유사도: 0.3141)\n",
      "  10위. 토론회 (키워드) (유사도: 0.3140)\n",
      "  (소요 시간: 0.00초)\n",
      "\n",
      "==================================================\n",
      "모든 (필터링) 작업 완료.\n"
     ]
    }
   ],
   "source": [
    "# --- [헬퍼 함수: Top-K '필터링' 찾기] ---\n",
    "def find_top_k_filtered(query_name, query_type, target_type, k=20):\n",
    "    \"\"\"\n",
    "    하나의 쿼리(이름, 타입)를 받아,\n",
    "    전체 노드와 비교 후 'target_type'에 해당하는\n",
    "    가장 유사한 K개를 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        query_name (str): 쿼리할 단어 (예: '삼성전자')\n",
    "        query_type (str): 쿼리 단어의 타입 (예: '종목')\n",
    "        target_type (str): 찾고자 하는 결과의 타입 (예: '키워드')\n",
    "        k (int): 상위 K개\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 쿼리 벡터 찾기\n",
    "    query_vector = None\n",
    "    if query_type == '키워드':\n",
    "        if query_name in keyword_map:\n",
    "            query_vector = final_embeddings_cpu['keyword'][keyword_map[query_name]]\n",
    "    elif query_type == '종목':\n",
    "        if query_name in stock_map:\n",
    "            query_vector = final_embeddings_cpu['stock'][stock_map[query_name]]\n",
    "    \n",
    "    if query_vector is None:\n",
    "        print(f\"  오류: '{query_name}'의 벡터를 찾을 수 없습니다.\")\n",
    "        return []\n",
    "\n",
    "    # 2. 코사인 유사도 계산 (전체 노드 대상)\n",
    "    sim_scores = cosine_similarity(query_vector.reshape(1, -1), all_vectors_matrix)[0]\n",
    "    \n",
    "    # 3. 상위 인덱스 추출 (내림차순)\n",
    "    top_indices = np.argsort(sim_scores)[::-1]\n",
    "    \n",
    "    # 4. 결과 리스트 생성 (필터링 적용)\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        if len(results) >= k:\n",
    "            # target_type K개를 모두 찾았으면 중단\n",
    "            break\n",
    "            \n",
    "        item_name, item_type = all_nodes_list[idx]\n",
    "        \n",
    "        # (필터링 1) 자기 자신은 건너뛰기\n",
    "        if item_name == query_name:\n",
    "            continue\n",
    "            \n",
    "        # (필터링 2) 원하는 target_type이 아니면 건너뛰기\n",
    "        if item_type != target_type:\n",
    "            continue\n",
    "            \n",
    "        score = sim_scores[idx]\n",
    "        results.append((item_name, item_type, score))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# --- [1번 작업: 키워드 10개 -> Top 20 '종목'] ---\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🔍 [작업 1] 랜덤 키워드 10개에 대한 TOP 20 '종목' (Keyword-to-Stock)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "N_QUERIES = 30\n",
    "\n",
    "# 1. 쿼리할 키워드 10개 샘플링\n",
    "if len(query_keywords) < N_QUERIES:\n",
    "    sampled_keywords = query_keywords\n",
    "else:\n",
    "    sampled_keywords = np.random.choice(query_keywords, N_QUERIES, replace=False)\n",
    "\n",
    "# 2. 10개 쿼리 실행\n",
    "for i, query_name in enumerate(sampled_keywords):\n",
    "    print(f\"\\n--- [1-{i+1:2d}] 쿼리: '{query_name}' (키워드) ---\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # (수정) target_type='종목' 으로 설정\n",
    "    top_k_results = find_top_k_filtered(query_name, '키워드', target_type='종목', k=10)\n",
    "    \n",
    "    if not top_k_results:\n",
    "        print(\"  유사한 '종목' 노드를 찾지 못했습니다.\")\n",
    "        continue\n",
    "        \n",
    "    for rank, (name, n_type, score) in enumerate(top_k_results):\n",
    "        print(f\"  {rank+1:2d}위. {name} ({n_type}) (유사도: {score:.4f})\")\n",
    "    print(f\"  (소요 시간: {time.time() - start_time:.2f}초)\")\n",
    "\n",
    "\n",
    "# --- [2번 작업: 종목 10개 -> Top 20 '키워드'] ---\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📈 [작업 2] 랜덤 종목 10개에 대한 TOP 20 '키워드' (Stock-to-Keyword)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. 쿼리할 종목 10개 샘플링\n",
    "if len(query_stocks) < N_QUERIES:\n",
    "    sampled_stocks = query_stocks\n",
    "else:\n",
    "    sampled_stocks = np.random.choice(query_stocks, N_QUERIES, replace=False)\n",
    "\n",
    "# 2. 10개 쿼리 실행\n",
    "for i, query_name in enumerate(sampled_stocks):\n",
    "    print(f\"\\n--- [2-{i+1:2d}] 쿼리: '{query_name}' (종목) ---\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # (수정) target_type='키워드' 로 설정\n",
    "    top_k_results = find_top_k_filtered(query_name, '종목', target_type='키워드', k=10)\n",
    "    \n",
    "    if not top_k_results:\n",
    "        print(\"  유사한 '키워드' 노드를 찾지 못했습니다.\")\n",
    "        continue\n",
    "        \n",
    "    for rank, (name, n_type, score) in enumerate(top_k_results):\n",
    "        print(f\"  {rank+1:2d}위. {name} ({n_type}) (유사도: {score:.4f})\")\n",
    "    print(f\"  (소요 시간: {time.time() - start_time:.2f}초)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"모든 (필터링) 작업 완료.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
