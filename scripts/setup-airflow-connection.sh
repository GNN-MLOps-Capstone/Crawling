#!/bin/bash

echo "ğŸ”— Setting up Airflow connection to News Data Database..."

# .envì—ì„œ ë¹„ë°€ë²ˆí˜¸ ì½ê¸°
if [ -f infrastructure/.env ]; then
    source infrastructure/.env
else
    echo "âŒ infrastructure/.env not found!"
    exit 1
fi

# Airflow scheduler ì»¨í…Œì´ë„ˆ ì´ë¦„ ì°¾ê¸°
SCHEDULER_CONTAINER=$(docker ps --filter "name=scheduler" --format "{{.Names}}" | head -1)

if [ -z "$SCHEDULER_CONTAINER" ]; then
    echo "âŒ Airflow scheduler container not found!"
    echo "Please start Airflow first."
    exit 1
fi

# Connection ì¶”ê°€
docker exec $SCHEDULER_CONTAINER airflow connections add news_data_db \
    --conn-type postgres \
    --conn-host news-data-postgres \
    --conn-login dobi \
    --conn-password "$DATA_DB_PASSWORD" \
    --conn-port 5432 \
    --conn-schema newscapstone \
    --conn-description "News capstone data storage database" \
    2>/dev/null && echo "âœ… Connection created" || echo "âš ï¸  Connection already exists"

# Connection í™•ì¸
echo ""
echo "ğŸ“‹ Verifying connection:"
docker exec $SCHEDULER_CONTAINER airflow connections get news_data_db

echo ""
echo "âœ… Connection setup complete!"
echo "   Connection ID: news_data_db"
echo "   Database: newscapstone"
echo "   User: dobi"
echo "   You can now use this in your DAGs"
